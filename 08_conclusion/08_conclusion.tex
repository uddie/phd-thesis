\chapter{Conclusion}
\label{08_chp:conclusion}

Developing systems that can understand and communicate in natural language is an ultimate goal of NLP and AI research. In this thesis, we focused on the aspect of common grounding as the key requisite for truly reliable conversation.

In Chapter \ref{02_chp:literature_review}, we gave an overview of the existing research related to common grounding. First, we introduced the theoretical foundations of common grounding in philosophy, mathematical logic and pyscholinguistics. Then, we explained the computational approaches to common grounding, including the general literature on dialogue system engineering. Finally, we discussed the important links to the problem of symbol grounding, which is deeply related to common grounding (especially in situated dialogues). Overall, we clarified the limitations of existing research and emphasized the importance of our research in these broader contexts.

In Chapter \ref{03_chp:task_formulation}, we introduced a novel task setting under continuous and partially-observable context. Following this idea, we designed a minimal collaborative reference task and developed OneCommon Corpus containing 6,760 dialogues. Through our dataset analysis, we verified advanced common grounding required in this setting, such as the  collaborative resolution of complex ambiguity, uncertainty and misunderstandings. As a preliminary experiment, we evaluated a simple baseline model on the target selection task and verified the difficulty of even recognizing the common ground. 

In Chapter \ref{04_chp:interpretation}, we proposed a method of decomposing common grounding based on its subtask of reference resolution. Based on our simple and generic framework, we annotated 5,191 successful dialogues from OneCommon Corpus which capture genuine ambiguity while maintaining reliability. Our dataset analysis demonstrated the importance of our annotation for interpreting the intermediate process of common grounding. Finally, we built end-to-end dialogue systems as the baselines for our proposed dataset. Our annotation helped improve and interpret their common grounding strategies, but substantial room remained for further improvement.

In Chapter \ref{05_chp:analysis}, we conducted further analyses of OneCommon Corpus based on spatial expressions. Specifically, we leveraged the existing annotation of referring expressions to annotate their spatial predicates (including modifications) efficiently and reliably. Although our annotation size is relatively small (600 dialogues), we revealed important linguistic structures in our dataset, i.e. predicate-argument structure, modification and ellipsis. Finally, through our extensive experiments, we showed how and where the current baselines struggle in capturing such precise structures.

In Chapter \ref{06_chp:task_generalization}, we further take into account the task setting under dynamic environments. To evaluate and analyze the ability of mainining common ground, we formulated the sequential collaborative reference task and collected Dynamic-OneCommon Corpus containing 5,617 dialogues. Our dataset analyses demonstrated sophisticated strategies required in this setting, such as the usage of spatio-temporal expressions and references to previous common ground. In our experiments, we conducted thorough evaluation of the end-to-end dialogue systems based on this dataset. Overall, we showed that there remains significant room left for improvement due to the requirement of even more advanced common grounding strategies.

In Chapter \ref{07_chp:discussion}, we briefly explored the future prospects of our research. In terms of the task design methodologies, we expect the view of \citet{pickering2004toward} will be crucial for the next-generation task formulations reflecting fully advanced common grounding. Next, we gave an overview of the promising directions to further improve the model performances in terms of common grounding. Finally, we illustrated several potential applications of our contributions in the practical, real-world settings.

All together, we expect this thesis to be a fundamental basis for realizing truly reliable communication between humans and computers. All of our resources are publicly available to facilitate future research, and we hope they will encourage further analyses and improvements of dialogue systems in terms of advanced common grounding.
