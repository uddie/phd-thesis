@book{herskovits1987language,
  title={Language and spatial cognition},
  author={Herskovits, Annette},
  year={1987},
  publisher={Cambridge university press}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@book{murphy2012machine,
  title={Machine learning: a probabilistic perspective},
  author={Murphy, Kevin P},
  year={2012},
  publisher={MIT press}
}

@book{pearl2009causality,
author = {Pearl, Judea},
title = {Causality: Models, Reasoning and Inference},
year = {2009},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd},
abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive
exposition of modern analysis of causation. It shows how causality has grown from
a nebulous concept into a mathematical theory with significant applications in the
fields of statistics, artificial intelligence, economics, philosophy, cognitive science,
and the health and social sciences. Judea Pearl presents and unifies the probabilistic,
manipulative, counterfactual, and structural approaches to causation and devises simple
mathematical tools for studying the relationships between causal connections and statistical
associations. The book will open the way for including causal analysis in the standard
curricula of statistics, artificial intelligence, business, epidemiology, social sciences,
and economics. Students in these fields will find natural models, simple inferential
procedures, and precise mathematical definitions of causal concepts that traditional
texts have evaded or made unduly complicated. The first edition of Causality has led
to a paradigmatic change in the way that causality is treated in statistics, philosophy,
computer science, social science, and economics. Cited in more than 3,000 scientific
publications, it continues to liberate scientists from the traditional molds of statistical
thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers'
questions, and offers a panoramic view of recent advances in this field of research.
Causality will be of interests to students and professionals in a wide variety of
fields. Anyone who wishes to elucidate meaningful relationships from data, predict
effects of actions and policies, assess explanations of reported events, or form theories
of causal understanding and causal speech will find this book stimulating and invaluable.}
}

@book{pearl2018book,
  title={The book of why: the new science of cause and effect},
  author={Pearl, Judea and Mackenzie, Dana},
  year={2018},
  publisher={Basic books}
}

@inproceedings{banko2007,
  author = {Banko, Michele and Cafarella, Michael J. and Soderland, Stephen and Broadhead, Matt and Etzioni, Oren},
  booktitle = {Proceedings of the 20th International Joint Conference on Artifical Intelligence},
  pages = {2670--2676},
  title = {Open Information Extraction from the Web},
  year = 2007
}

@inproceedings{Aggarwal2012MiningTD,
  title={Mining Text Data},
  author={C. Aggarwal and ChengXiang Zhai},
  booktitle={Springer US},
  year={2012}
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 volume = {25},
 year = {2012}
}


@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}

@inproceedings{sugawara2017prerequisite,
  title={Prerequisite Skills for Reading Comprehension: Multi-Perspective Analysis of MCTest Datasets and Systems.},
  author={Sugawara, Saku and Yokono, Hikaru and Aizawa, Akiko},
  booktitle={AAAI},
  pages={3089--3096},
  year={2017}
}

@article{de2020towards,
  title={Towards ecologically valid research on language user interfaces},
  author={De Vries, Harm and Bahdanau, Dzmitry and Manning, Christopher},
  journal={arXiv preprint arXiv:2007.14435},
  year={2020}
}

@incollection{bezier1974mathematical,
  title={Mathematical and practical possibilities of {UNISURF}},
  author={B\'{e}zier, Pierre},
  booktitle={Computer Aided Geometric Design},
  pages={127--152},
  year={1974},
  publisher={Elsevier}
}

@inproceedings{gotze-boye-2016-spaceref,
    title = "{S}pace{R}ef: A corpus of street-level geographic descriptions",
    author = {G{\"o}tze, Jana  and
      Boye, Johan},
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    pages = "3822--3827",
    abstract = "This article describes SPACEREF, a corpus of street-level geographic descriptions. Pedestrians are walking a route in a (real) urban environment, describing their actions. Their position is automatically logged, their speech is manually transcribed, and their references to objects are manually annotated with respect to a crowdsourced geographic database. We describe how the data was collected and annotated, and how it has been used in the context of creating resources for an automatic pedestrian navigation system.",
}

@article{ilinykh2019meetup,
  title={MeetUp! A Corpus of Joint Activity Dialogues in a Visual Environment},
  author={Ilinykh, Nikolai and Zarrie{\ss}, Sina and Schlangen, David},
  journal={arXiv preprint arXiv:1907.05084},
  year={2019}
}

@misc{olah2015understanding,
title = {Understanding {LSTM} Networks},
author  = {Christopher Olah},
year  = {2015},
URL = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
note = {Last accessed on June 4, 2021}, 
}

@inproceedings{ribeiro-etal-2019-red,
    title = "Are Red Roses Red? Evaluating Consistency of Question-Answering Models",
    author = "Ribeiro, Marco Tulio  and
      Guestrin, Carlos  and
      Singh, Sameer",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "6174--6184",
}

@inproceedings{udagawa2019natural,
  title={A Natural Language Corpus of Common Grounding under Continuous and Partially-Observable Context},
  author={Udagawa, Takuma and Aizawa, Akiko},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={7120--7127},
  year={2019}
}

@inproceedings{udagawa2020annotated,
  title={An Annotated Corpus of Reference Resolution for Interpreting Common Grounding},
  author={Udagawa, Takuma and Aizawa, Akiko},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={9081--9089},
  year={2020}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{sugawara-etal-2021-benchmarking,
    title = "Benchmarking Machine Reading Comprehension: A Psychological Perspective",
    author = "Sugawara, Saku  and
      Stenetorp, Pontus  and
      Aizawa, Akiko",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "1592--1612",
    abstract = "Machine reading comprehension (MRC) has received considerable attention as a benchmark for natural language understanding. However, the conventional task design of MRC lacks explainability beyond the model interpretation, i.e., reading comprehension by a model cannot be explained in human terms. To this end, this position paper provides a theoretical basis for the design of MRC datasets based on psychology as well as psychometrics, and summarizes it in terms of the prerequisites for benchmarking MRC. We conclude that future datasets should (i) evaluate the capability of the model for constructing a coherent and grounded representation to understand context-dependent situations and (ii) ensure substantive validity by shortcut-proof questions and explanation as a part of the task design.",
}

@inproceedings{udagawa-etal-2020-linguistic,
    title = "A Linguistic Analysis of Visually Grounded Dialogues Based on Spatial Expressions",
    author = "Udagawa, Takuma  and
      Yamazaki, Takato  and
      Aizawa, Akiko",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "750--765",
    abstract = "Recent models achieve promising results in visually grounded dialogues. However, existing datasets often contain undesirable biases and lack sophisticated linguistic analyses, which make it difficult to understand how well current models recognize their precise linguistic structures. To address this problem, we make two design choices: first, we focus on OneCommon Corpus (CITATION), a simple yet challenging common grounding dataset which contains minimal bias by design. Second, we analyze their linguistic structures based on spatial expressions and provide comprehensive and reliable annotation for 600 dialogues. We show that our annotation captures important linguistic structures including predicate-argument structure, modification and ellipsis. In our experiments, we assess the model{'}s understanding of these structures through reference resolution. We demonstrate that our annotation can reveal both the strengths and weaknesses of baseline models in essential levels of detail. Overall, we propose a novel framework and resource for investigating fine-grained language understanding in visually grounded dialogues.",
}

@article{udagawa2021maintaining,
  title = "Maintaining Common Ground in Dynamic Environments",
  author = {Udagawa, Takuma and Aizawa, Akiko},
  journal = {Transactions of the Association for Computational Linguistics},
  year = {2021},
  volume =  "9",
}

@inproceedings{chen-etal-2019-towards,
    title = "Towards Knowledge-Based Recommender Dialog System",
    author = "Chen, Qibin  and
      Lin, Junyang  and
      Zhang, Yichang  and
      Ding, Ming  and
      Cen, Yukuo  and
      Yang, Hongxia  and
      Tang, Jie",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "1803--1813",
    abstract = "In this paper, we propose a novel end-to-end framework called KBRD, which stands for Knowledge-Based Recommender Dialog System. It integrates the recommender system and the dialog generation system. The dialog generation system can enhance the performance of the recommendation system by introducing information about users{'} preferences, and the recommender system can improve that of the dialog generation system by providing recommendation-aware vocabulary bias. Experimental results demonstrate that our proposed model has significant advantages over the baselines in both the evaluation of dialog generation and recommendation. A series of analyses show that the two systems can bring mutual benefits to each other, and the introduced knowledge contributes to both their performances.",
}

@inproceedings{de2017guesswhat,
  title = {GuessWhat?! Visual object discovery through multi-modal dialogue},
  author = {De Vries, Harm and Strub, Florian and Chandar, Sarath and Pietquin, Olivier and Larochelle, Hugo and Courville, Aaron},
  booktitle = {Proc. of CVPR},
  year = {2017}
}

@inproceedings{zarriess-etal-2016-pentoref,
    title = "{P}ento{R}ef: A Corpus of Spoken References in Task-oriented Dialogues",
    author = "Zarrie{\ss}, Sina  and
      Hough, Julian  and
      Kennington, Casey  and
      Manuvinakurike, Ramesh  and
      DeVault, David  and
      Fern{\'a}ndez, Raquel  and
      Schlangen, David",
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    pages = "125--131"
}

@article{Goodman2016PragmaticLI,
  title={Pragmatic Language Interpretation as Probabilistic Inference},
  author={Noah D. Goodman and Michael C. Frank},
  journal={Trends in Cognitive Sciences},
  year={2016},
  volume={20},
  pages={818-829}
}

@inproceedings{Carreira2017QuoVA,
  title={{Q}uo Vadis, Action Recognition? {A} New Model and the Kinetics Dataset},
  author={J. Carreira and Andrew Zisserman},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017},
  pages={4724--4733}
}

@inproceedings{wang2018non,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7794--7803},
  year={2018}
}

@inproceedings{lu2019vilbert,
  title={{V}i{LBERT}: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13--23},
  year={2019}
}

@inproceedings{le-etal-2020-bist,
    title = "{B}i{ST}: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues",
    author = "Le, Hung  and
      Sahoo, Doyen  and
      Chen, Nancy  and
      Hoi, Steven C.H.",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
    year = "2020",
    pages = "1846--1859",
}

@inproceedings{sharma-etal-2018-conceptual,
    title = "Conceptual Captions: {A} Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning",
    author = "Sharma, Piyush  and
      Ding, Nan  and
      Goodman, Sebastian  and
      Soricut, Radu",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
    year = "2018",
    pages = "2556--2565",
}

@inproceedings{tracktor_2019_ICCV,
  author = {Bergmann, Philipp and Meinhardt, Tim and Leal{-}Taix{\'{e}}, Laura},
  title = {Tracking Without Bells and Whistles},
  booktitle = {International Conference on Computer Vision},
  year = {2019}
}

@inproceedings{wang2020towards,
  author = {Wang, Zhongdao and Zheng, Liang and Liu, Yixuan and Wang, Shengjin},
  title = {Towards Real-Time Multi-Object Tracking},
  booktitle = {European Conference on Computer Vision},
  year = {2020}
}

@article{Hawkins2021TheDO,
  title={The Division of Labor in Communication: Speakers Help Listeners Account for Asymmetries in Visual Perspective},
  author={Robert X. D. Hawkins and H. Gweon and Noah D. Goodman},
  journal={Cognitive science},
  year={2021},
  volume={45 3},
  pages={e12926}
}

@inproceedings{mcdowell-goodman-2019-learning,
    title = "Learning from Omission",
    author = "McDowell, Bill  and
      Goodman, Noah",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "619--628",
    abstract = "Pragmatic reasoning allows humans to go beyond the literal meaning when interpret- ing language in context. Previous work has shown that such reasoning can improve the performance of already-trained language understanding systems. Here, we explore whether pragmatic reasoning during training can improve the quality of learned meanings. Our experiments on reference game data show that end-to-end pragmatic training produces more accurate utterance interpretation models, especially when data is sparse and language is complex.",
}

@inproceedings{kottur-etal-2017-natural,
    title = "Natural Language Does Not Emerge {`}Naturally{'} in Multi-Agent Dialog",
    author = "Kottur, Satwik  and
      Moura, Jos{\'e}  and
      Lee, Stefan  and
      Batra, Dhruv",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    pages = "2962--2967",
    abstract = "A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, learned without any human supervision! In this paper, using a Task {\&} Talk reference game between two agents as a testbed, we present a sequence of {`}negative{'} results culminating in a {`}positive{'} one {--} showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge {`}naturally{'},despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate.",
}

@inproceedings{mordatch2018emergence,
  title={Emergence of grounded compositional language in multi-agent populations},
  author={Mordatch, Igor and Abbeel, Pieter},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{iki2020language,
  title={Language-Conditioned Feature Pyramids for Visual Selection Tasks},
  author={Iki, Taichi and Aizawa, Akiko},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings},
  pages={4687--4697},
  year={2020}
}

@inproceedings{jang2020bayes,
  title={Bayes-adaptive monte-carlo planning and learning for goal-oriented dialogues},
  author={Jang, Youngsoo and Lee, Jongmin and Kim, Kee-Eung},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={7994--8001},
  year={2020}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{poesio2010completions,
  title={Completions, coordination, and alignment in dialogue},
  author={Poesio, Massimo and Rieser, Hannes},
  journal={Dialogue \& Discourse},
  volume={1},
  number={1},
  year={2010}
}

@inproceedings{haber-etal-2019-photobook,
    title = "The {P}hoto{B}ook Dataset: Building Common Ground through Visually-Grounded Dialogue",
    author = {Haber, Janosch  and
      Baumg{\"a}rtner, Tim  and
      Takmaz, Ece  and
      Gelderloos, Lieke  and
      Bruni, Elia  and
      Fern{\'a}ndez, Raquel},
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "1895--1910",
    abstract = "This paper introduces the PhotoBook dataset, a large-scale collection of visually-grounded, task-oriented dialogues in English designed to investigate shared dialogue history accumulating during conversation. Taking inspiration from seminal work on dialogue analysis, we propose a data-collection task formulated as a collaborative game prompting two online participants to refer to images utilising both their visual context as well as previously established referring expressions. We provide a detailed description of the task setup and a thorough analysis of the 2,500 dialogues collected. To further illustrate the novel features of the dataset, we propose a baseline model for reference resolution which uses a simple method to take into account shared information accumulated in a reference chain. Our results show that this information is particularly important to resolve later descriptions and underline the need to develop more sophisticated models of common ground in dialogue interaction.",
}

@inproceedings{das2017visual,
  title={Visual dialog},
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  volume={2},
  year={2017}
}

@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{grosz1996collaborative,
  title={Collaborative systems (AAAI-94 presidential address)},
  author={Grosz, Barbara J},
  journal={AI magazine},
  volume={17},
  number={2},
  pages={67--67},
  year={1996}
}

@book{stalnaker1978assertion,
  title={Assertion},
  author={Stalnaker, Robert C},
  year={1978},
  publisher={Wiley Online Library}
}

@book{clark1996using,
  title={Using language},
  author={Clark, Herbert H},
  year={1996},
  publisher={Cambridge university press}
}

@article{steels1997synthetic,
  title={The synthetic modeling of language origins},
  author={Steels, Luc},
  journal={Evolution of communication},
  volume={1},
  number={1},
  pages={1--34},
  year={1997},
  publisher={John Benjamins}
}

@book{levinson2001language,
  title={Language acquisition and conceptual development},
  author={Levinson, Stephen C and Bowerman, Melissa},
  year={2001},
  publisher={Cambridge University Press}
}

@book{Chomsky1957-CHOSS-2,
  title = {Syntactic Structures},
  publisher = {Mouton},
  year = {1957},
  author = {Noam Chomsky}
}

@book{elman1996rethinking,
  title={Rethinking innateness: A connectionist perspective on development},
  author={Elman, Jeffrey L and Bates, Elizabeth A and Johnson, Mark H},
  volume={10},
  year={1996},
  publisher={MIT press}
}

@inproceedings{clark2001grounding,
  title={Grounding and attention in language acquisition},
  author={Clark, Eve V and Grossman, James B},
  booktitle={Papers from the 37th meeting of the Chicago Linguistic Society},
  volume={1},
  pages={95--116},
  year={2001}
}

@InProceedings{Das_2017_ICCV,
author = {Das, Abhishek and Kottur, Satwik and Moura, Jose M. F. and Lee, Stefan and Batra, Dhruv},
title = {Learning Cooperative Visual Dialog Agents With Deep Reinforcement Learning},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@InProceedings{liu2012perceptual,
  author =  "Liu, Changsong
    and Fang, Rui
    and Chai, Joyce",
  title =   "Towards Mediating Shared Perceptual Basis in Situated Dialogue",
  booktitle =   "Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
  year =  "2012",
  publisher =   "Association for Computational Linguistics",
  pages =   "140--149",
  location =  "Seoul, South Korea",
}

@inproceedings{suhr2017corpus,
  title={A corpus of natural language for visual reasoning},
  author={Suhr, Alane and Lewis, Mike and Yeh, James and Artzi, Yoav},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  volume={2},
  pages={217--223},
  year={2017}
}

@inproceedings{dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021}
}

@InProceedings{Wu_2018_CVPR,
author = {Wu, Qi and Wang, Peng and Shen, Chunhua and Reid, Ian and van den Hengel, Anton},
title = {Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@inproceedings{DBLP:conf/icml/YaratsL18,
  author    = {Denis Yarats and
               Mike Lewis},
  title     = {Hierarchical Text Generation and Planning for Strategic Dialogue},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  pages     = {5587--5595},
  year      = {2018},
  timestamp = {Fri, 13 Jul 2018 14:58:25 +0200},
}

@InProceedings{Kottur_2018_ECCV,
author = {Kottur, Satwik and Moura, Jose M. F. and Parikh, Devi and Batra, Dhruv and Rohrbach, Marcus},
title = {Visual Coreference Resolution in Visual Dialog using Neural Module Networks},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@inproceedings{shekhar-etal-2019-beyond,
    title = "Beyond task success: A closer look at jointly learning to see, ask, and {G}uess{W}hat",
    author = {Shekhar, Ravi  and
      Venkatesh, Aashish  and
      Baumg{\"a}rtner, Tim  and
      Bruni, Elia  and
      Plank, Barbara  and
      Bernardi, Raffaella  and
      Fern{\'a}ndez, Raquel},
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pages = "2578--2587",
    abstract = "We propose a grounded dialogue state encoder which addresses a foundational issue on how to integrate visual grounding with dialogue system components. As a test-bed, we focus on the GuessWhat?! game, a two-player game where the goal is to identify an object in a complex visual scene by asking a sequence of yes/no questions. Our visually-grounded encoder leverages synergies between guessing and asking questions, as it is trained jointly using multi-task learning. We further enrich our model via a cooperative learning regime. We show that the introduction of both the joint architecture and cooperative learning lead to accuracy improvements over the baseline system. We compare our approach to an alternative system which extends the baseline with reinforcement learning. Our in-depth analysis shows that the linguistic skills of the two models differ dramatically, despite approaching comparable performance levels. This points at the importance of analyzing the linguistic output of competing systems beyond numeric comparison solely based on task success.",
}

@inproceedings{gan-etal-2019-multi,
    title = "Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog",
    author = "Gan, Zhe  and
      Cheng, Yu  and
      Kholy, Ahmed  and
      Li, Linjie  and
      Liu, Jingjing  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "6463--6474",
    abstract = "This paper presents a new model for visual dialog, Recurrent Dual Attention Network (ReDAN), using multi-step reasoning to answer a series of questions about an image. In each question-answering turn of a dialog, ReDAN infers the answer progressively through multiple reasoning steps. In each step of the reasoning process, the semantic representation of the question is updated based on the image and the previous dialog history, and the recurrently-refined representation is used for further reasoning in the subsequent step. On the VisDial v1.0 dataset, the proposed ReDAN model achieves a new state-of-the-art of 64.47{\%} NDCG score. Visualization on the reasoning process further demonstrates that ReDAN can locate context-relevant visual and textual clues via iterative refinement, which can lead to the correct answer step-by-step.",
}

@InProceedings{niu2019recursive,
    author = {Niu, Yulei and Zhang, Hanwang and Zhang, Manli and Zhang, Jianhong and Lu, Zhiwu and Wen, Ji-Rong},
    title = {Recursive Visual Attention in Visual Dialog},
    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2019}
}

@inproceedings{zheng2019reasoning,
    title={Reasoning Visual Dialogs with Structural and Partial Observations},
    author={Zheng, Zilong and Wang, Wenguan and Qi, Siyuan and Zhu, Song-Chun},
    booktitle={Computer Vision and Pattern Recognition (CVPR), 2019 IEEE Conference on},
    year={2019}
}

@inproceedings{kang-etal-2019-dual,
    title = "Dual Attention Networks for Visual Reference Resolution in Visual Dialog",
    author = "Kang, Gi-Cheon  and
      Lim, Jaeseo  and
      Zhang, Byoung-Tak",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "2024--2033",
    abstract = "Visual dialog (VisDial) is a task which requires a dialog agent to answer a series of questions grounded in an image. Unlike in visual question answering (VQA), the series of questions should be able to capture a temporal context from a dialog history and utilizes visually-grounded information. Visual reference resolution is a problem that addresses these challenges, requiring the agent to resolve ambiguous references in a given question and to find the references in a given image. In this paper, we propose Dual Attention Networks (DAN) for visual reference resolution in VisDial. DAN consists of two kinds of attention modules, REFER and FIND. Specifically, REFER module learns latent relationships between a given question and a dialog history by employing a multi-head attention mechanism. FIND module takes image features and reference-aware representations (i.e., the output of REFER module) as input, and performs visual grounding via bottom-up attention mechanism. We qualitatively and quantitatively evaluate our model on VisDial v1.0 and v0.9 datasets, showing that DAN outperforms the previous state-of-the-art model by a significant margin.",
}

@article{visdial_bert,
  title={Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline},
  author={Vishvak Murahari and Dhruv Batra and Devi Parikh and Abhishek Das},
  journal={arXiv preprint arXiv:1912.02379},
  year={2019},
}

@inproceedings{visdial_eval,
  title={Evaluating Visual Conversational Agents via Cooperative Human-AI Games},
  author={Prithvijit Chattopadhyay and Deshraj Yadav and Viraj Prabhu and Arjun Chandrasekaran and Abhishek Das and Stefan Lee and Dhruv Batra and Devi Parikh},
  booktitle={Proceedings of the Fifth AAAI Conference on Human Computation and Crowdsourcing (HCOMP)},
  year={2017}
}


@inproceedings{goyal2017making,
  title={Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6904--6913},
  year={2017}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
volume={115},
number={3},
pages={211-252}
}
@inproceedings{johnson2017clevr,
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens
          and Fei-Fei, Li and Zitnick, C Lawrence and Girshick, Ross},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{yi2020clevrer,
title={CLEVRER: Collision Events for Video Representation and Reasoning},
author={Kexin Yi and Chuang Gan and Yunzhu Li and Pushmeet Kohli and Jiajun Wu and Antonio Torralba and Joshua B. Tenenbaum},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{chen-etal-2018-attacking,
    title = "Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning",
    author = "Chen, Hongge  and
      Zhang, Huan  and
      Chen, Pin-Yu  and
      Yi, Jinfeng  and
      Hsieh, Cho-Jui",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    pages = "2587--2597",
    abstract = "Visual language grounding is widely studied in modern neural image captioning systems, which typically adopts an encoder-decoder framework consisting of two principal components: a convolutional neural network (CNN) for image feature extraction and a recurrent neural network (RNN) for language caption generation. To study the robustness of language grounding to adversarial perturbations in machine vision and perception, we propose Show-and-Fool, a novel algorithm for crafting adversarial examples in neural image captioning. The proposed algorithm provides two evaluation approaches, which check if we can mislead neural image captioning systems to output some randomly chosen captions or keywords. Our extensive experiments show that our algorithm can successfully craft visually-similar adversarial examples with randomly targeted captions or keywords, and the adversarial examples can be made highly transferable to other image captioning systems. Consequently, our approach leads to new robustness implications of neural image captioning and novel insights in visual language grounding.",
}

@article{massiceti2018visual,
  title={Visual dialogue without vision or dialogue},
  author={Massiceti, Daniela and Dokania, Puneet K and Siddharth, N and Torr, Philip HS},
  journal={arXiv preprint arXiv:1812.06417},
  year={2018}
}

@inproceedings{kottur-etal-2019-clevr,
    title = "{CLEVR}-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual Dialog",
    author = "Kottur, Satwik  and
      Moura, Jos{\'e} M. F.  and
      Parikh, Devi  and
      Batra, Dhruv  and
      Rohrbach, Marcus",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pages = "582--595",
    abstract = "Visual Dialog is a multimodal task of answering a sequence of questions grounded in an image (using the conversation history as context). It entails challenges in vision, language, reasoning, and grounding. However, studying these subtasks in isolation on large, real datasets is infeasible as it requires prohibitively-expensive complete annotation of the {`}state{'} of all images and dialogs. We develop CLEVR-Dialog, a large diagnostic dataset for studying multi-round reasoning in visual dialog. Specifically, we construct a dialog grammar that is grounded in the scene graphs of the images from the CLEVR dataset. This combination results in a dataset where all aspects of the visual dialog are fully annotated. In total, CLEVR-Dialog contains 5 instances of 10-round dialogs for about 85k CLEVR images, totaling to 4.25M question-answer pairs. We use CLEVR-Dialog to benchmark performance of standard visual dialog models; in particular, on visual coreference resolution (as a function of the coreference distance). This is the first analysis of its kind for visual dialog models that was not possible without this dataset. We hope the findings from CLEVR-Dialog will help inform the development of future models for visual dialog. Our code and dataset are publicly available.",
}

@inproceedings{sankar-etal-2019-neural,
    title = "Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study",
    author = "Sankar, Chinnadhurai  and
      Subramanian, Sandeep  and
      Pal, Chris  and
      Chandar, Sarath  and
      Bengio, Yoshua",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "32--37",
    abstract = "Neural generative models have been become increasingly popular when building conversational agents. They offer flexibility, can be easily adapted to new domains, and require minimal domain engineering. A common criticism of these systems is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these models use the available dialog history by studying the sensitivity of the models to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our code, we believe that it will serve as a useful diagnostic tool for evaluating dialog systems in the future.",
}

@inproceedings{kim2020modality,
  title={Modality-Balanced Models for Visual Dialogue},
  author={Kim, Hyounghun and Tan, Hao and Bansal, Mohit},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={8091--8098},
  year={2020}
}

@inproceedings{pustejovsky2011iso,
  title={ISO-Space: The annotation of spatial information in language},
  author={Pustejovsky, James and Moszkowicz, Jessica L and Verhagen, Marc},
  booktitle={Proceedings of the Sixth Joint ISO-ACL SIGSEM Workshop on Interoperable Semantic Annotation},
  volume={6},
  pages={1--9},
  year={2011}
}

@inproceedings{dan-etal-2020-spatial,
    title = "From Spatial Relations to Spatial Configurations",
    author = "Dan, Soham  and
      Kordjamshidi, Parisa  and
      Bonn, Julia  and
      Bhatia, Archna  and
      Cai, Zheng  and
      Palmer, Martha  and
      Roth, Dan",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    pages = "5855--5864",
    abstract = "Spatial Reasoning from language is essential for natural language understanding. Supporting it requires a representation scheme that can capture spatial phenomena encountered in language as well as in images and videos.Existing spatial representations are not sufficient for describing spatial configurations used in complex tasks. This paper extends the capabilities of existing spatial representation languages and increases coverage of the semantic aspects that are needed to ground spatial meaning of natural language text in the world. Our spatial relation language is able to represent a large, comprehensive set of spatial concepts crucial for reasoning and is designed to support composition of static and dynamic spatial configurations. We integrate this language with the Abstract Meaning Representation (AMR) annotation schema and present a corpus annotated by this extended AMR. To exhibit the applicability of our representation scheme, we annotate text taken from diverse datasets and show how we extend the capabilities of existing spatial representation languages with fine-grained decomposition of semantics and blend it seamlessly with AMRs of sentences and discourse representations as a whole.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{pustejovsky2011using,
  title={Using ISO-Space for annotating spatial information},
  author={Pustejovsky, James and Moszkowicz, Jessica L and Verhagen, Marc},
  booktitle={Proceedings of the International Conference on Spatial Information Theory},
  year={2011}
}

@inproceedings{petruck-ellsworth-2018-representing,
    title = "Representing Spatial Relations in {F}rame{N}et",
    author = "Petruck, Miriam R. L.  and
      Ellsworth, Michael J.",
    booktitle = "Proceedings of the First International Workshop on Spatial Language Understanding",
    month = jun,
    year = "2018",
    address = "New Orleans",
    publisher = "Association for Computational Linguistics",
    pages = "41--45",
    abstract = "While humans use natural language to express spatial relations between and across entities in the world with great facility, natural language systems have a facility that depends on that human facility. This position paper presents approach to representing spatial relations in language, and advocates its adoption for representing the meaning of spatial language. This work shows the importance of axis-orientation systems for capturing the complexity of spatial relations, which FrameNet encodes with semantic types.",
}

@inproceedings{rao-daume-iii-2018-learning,
    title = "Learning to Ask Good Questions: Ranking Clarification Questions using Neural Expected Value of Perfect Information",
    author = "Rao, Sudha  and
      Daum{\'e} III, Hal",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    pages = "2737--2746",
    abstract = "Inquiry is fundamental to communication, and machines cannot effectively collaborate with humans unless they can ask questions. In this work, we build a neural network model for the task of ranking clarification questions. Our model is inspired by the idea of expected value of perfect information: a good question is one whose expected answer will be useful. We study this problem using data from StackExchange, a plentiful online resource in which people routinely ask clarifying questions to posts so that they can better offer assistance to the original poster. We create a dataset of clarification questions consisting of 77K posts paired with a clarification question (and answer) from three domains of StackExchange: askubuntu, unix and superuser. We evaluate our model on 500 samples of this dataset against expert human judgments and demonstrate significant improvements over controlled baselines.",
}

@inproceedings{ulinski-etal-2019-spatialnet,
    title = "{S}patial{N}et: A Declarative Resource for Spatial Relations",
    author = "Ulinski, Morgan  and
      Coyne, Bob  and
      Hirschberg, Julia",
    booktitle = "Proceedings of the Combined Workshop on Spatial Language Understanding ({S}p{LU}) and Grounded Communication for Robotics ({R}obo{NLP})",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pages = "61--70",
    abstract = "This paper introduces SpatialNet, a novel resource which links linguistic expressions to actual spatial configurations. SpatialNet is based on FrameNet (Ruppenhofer et al., 2016) and VigNet (Coyne et al., 2011), two resources which use frame semantics to encode lexical meaning. SpatialNet uses a deep semantic representation of spatial relations to provide a formal description of how a language expresses spatial information. This formal representation of the lexical semantics of spatial language also provides a consistent way to represent spatial meaning across multiple languages. In this paper, we describe the structure of SpatialNet, with examples from English and German. We also show how SpatialNet can be combined with other existing NLP tools to create a text-to-scene system for a language.",
}

@inproceedings{suhr-etal-2019-executing,
    title = "Executing Instructions in Situated Collaborative Interactions",
    author = "Suhr, Alane  and
      Yan, Claudia  and
      Schluger, Jack  and
      Yu, Stanley  and
      Khader, Hadi  and
      Mouallem, Marwa  and
      Zhang, Iris  and
      Artzi, Yoav",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "2119--2130",
    abstract = "We study a collaborative scenario where a user not only instructs a system to complete tasks, but also acts alongside it. This allows the user to adapt to the system abilities by changing their language or deciding to simply accomplish some tasks themselves, and requires the system to effectively recover from errors as the user strategically assigns it new goals. We build a game environment to study this scenario, and learn to map user instructions to system actions. We introduce a learning approach focused on recovery from cascading errors between instructions, and modeling methods to explicitly reason about instructions with multiple goals. We evaluate with a new evaluation protocol using recorded interactions and online games with human users, and observe how users adapt to the system abilities.",
}

@inproceedings{ilinykh-etal-2019-meet,
    title = "Meet Up! A Corpus of Joint Activity Dialogues in a Visual Environment",
    author = "Ilinykh, Nikolai  and
      Zarrie{\ss}, Sina  and
      Schlangen, David",
    booktitle = "Proceedings of the 23rd Workshop on the Semantics and Pragmatics of Dialogue - Full Papers",
    month = sep,
    year = "2019",
    address = "London, United Kingdom",
    publisher = "SEMDIAL",
}

@inproceedings{chen2019touchdown,
  title={Touchdown: Natural language navigation and spatial reasoning in visual street environments},
  author={Chen, Howard and Suhr, Alane and Misra, Dipendra and Snavely, Noah and Artzi, Yoav},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={12538--12547},
  year={2019}
}

@inproceedings{suhr-etal-2017-corpus,
    title = "A Corpus of Natural Language for Visual Reasoning",
    author = "Suhr, Alane  and
      Lewis, Mike  and
      Yeh, James  and
      Artzi, Yoav",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "217--223",
    abstract = "We present a new visual reasoning language dataset, containing 92,244 pairs of examples of natural statements grounded in synthetic images with 3,962 unique sentences. We describe a method of crowdsourcing linguistically-diverse data, and present an analysis of our data. The data demonstrates a broad set of linguistic phenomena, requiring visual and set-theoretic reasoning. We experiment with various models, and show the data presents a strong challenge for future research.",
}

@inproceedings{suhr-etal-2019-corpus,
    title = "A Corpus for Reasoning about Natural Language Grounded in Photographs",
    author = "Suhr, Alane  and
      Zhou, Stephanie  and
      Zhang, Ally  and
      Zhang, Iris  and
      Bai, Huajun  and
      Artzi, Yoav",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "6418--6428",
    abstract = "We introduce a new dataset for joint reasoning about natural language and images, with a focus on semantic diversity, compositionality, and visual reasoning challenges. The data contains 107,292 examples of English sentences paired with web photographs. The task is to determine whether a natural language caption is true about a pair of photographs. We crowdsource the data using sets of visually rich images and a compare-and-contrast task to elicit linguistically diverse language. Qualitative analysis shows the data requires compositional joint reasoning, including about quantities, comparisons, and relations. Evaluation using state-of-the-art visual reasoning methods shows the data presents a strong challenge.",
}

@inproceedings{shi-etal-2019-unsupervised,
    title = "Unsupervised Dialog Structure Learning",
    author = "Shi, Weiyan  and
      Zhao, Tiancheng  and
      Yu, Zhou",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pages = "1797--1807",
    abstract = "Learning a shared dialog structure from a set of task-oriented dialogs is an important challenge in computational linguistics. The learned dialog structure can shed light on how to analyze human dialogs, and more importantly contribute to the design and evaluation of dialog systems. We propose to extract dialog structures using a modified VRNN model with discrete latent vectors. Different from existing HMM-based models, our model is based on variational-autoencoder (VAE). Such model is able to capture more dynamics in dialogs beyond the surface forms of the language. We find that qualitatively, our method extracts meaningful dialog structure, and quantitatively, outperforms previous models on the ability to predict unseen data. We further evaluate the model{'}s effectiveness in a downstream task, the dialog system building task. Experiments show that, by integrating the learned dialog structure into the reward function design, the model converges faster and to a better outcome in a reinforcement learning setting.",
}

@article{zhou2020design,
  title={The design and implementation of xiaoice, an empathetic social chatbot},
  author={Zhou, Li and Gao, Jianfeng and Li, Di and Shum, Heung-Yeung},
  journal={Computational Linguistics},
  volume={46},
  number={1},
  pages={53--93},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{NIPS2015_14bfa6bb,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 volume = {28},
 year = {2015}
}

@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@article{ram2018conversational,
  title={Conversational AI: The science behind the alexa prize},
  author={Ram, Ashwin and Prasad, Rohit and Khatri, Chandra and Venkatesh, Anu and Gabriel, Raefer and Liu, Qing and Nunn, Jeff and Hedayatnia, Behnam and Cheng, Ming and Nagar, Ashish and others},
  journal={arXiv preprint arXiv:1801.03604},
  year={2018}
}

@incollection{bunt2017dialogue,
  title={Dialogue act annotation with the ISO 24617-2 standard},
  author={Bunt, Harry and Petukhova, Volha and Traum, David and Alexandersson, Jan},
  booktitle={Multimodal Interaction with W3C Standards},
  pages={109--135},
  year={2017},
  publisher={Springer}
}

@inproceedings{pustejovsky2015semeval,
  title={SemEval-2015 Task 8: SpaceEval},
  author={Pustejovsky, James and Kordjamshidi, Parisa and Moens, Marie-Francine and Levine, Aaron and Dworman, Seth and Yocum, Zachary},
  booktitle={Proceedings of the 9th International Workshop on Semantic Evaluation (semeval 2015)},
  pages={884--894},
  year={2015},
  organization={ACL}
}

@inproceedings{kordjamshidi-etal-2010-spatial,
    title = "Spatial Role Labeling: Task Definition and Annotation Scheme",
    author = "Kordjamshidi, Parisa  and
      Otterlo, Martijn Van  and
      Moens, Marie-Francine",
    booktitle = "Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)",
    year = "2010",
    address = "Valletta, Malta",
    publisher = "European Language Resources Association (ELRA)",
}

@inproceedings{elliott-keller-2013-image,
    title = "Image Description using Visual Dependency Representations",
    author = "Elliott, Desmond  and
      Keller, Frank",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    pages = "1292--1302",
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International Journal of Computer Vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{li-etal-2016-persona,
    title = "A Persona-Based Neural Conversation Model",
    author = "Li, Jiwei  and
      Galley, Michel  and
      Brockett, Chris  and
      Spithourakis, Georgios  and
      Gao, Jianfeng  and
      Dolan, Bill",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    pages = "994--1003",
}

@inproceedings{roth-yih-2004-linear,
    title = "A Linear Programming Formulation for Global Inference in Natural Language Tasks",
    author = "Roth, Dan  and
      Yih, Wen-tau",
    booktitle = "Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004",
    year = "2004",
    address = "Boston, Massachusetts, USA",
    publisher = "Association for Computational Linguistics",
    pages = "1--8",
}


@article{young2013pomdp,
  title={{POMDP}-based statistical spoken dialog systems: A review},
  author={Young, Steve and Ga{\v{s}}i{\'c}, Milica and Thomson, Blaise and Williams, Jason D},
  journal={Proceedings of the IEEE},
  volume={101},
  number={5},
  pages={1160--1179},
  year={2013},
  publisher={IEEE}
}

@inproceedings{hansen2020you,
  title={What Do You Mean 'Why?': Resolving Sluices in Conversations},
  author={Hansen, Victor Petr{\'e}n Bach and S{\o}gaard, Anders},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={7887--7894},
  year={2020}
}

@inproceedings{quan-etal-2019-gecor,
    title = "{GECOR}: An End-to-End Generative Ellipsis and Co-reference Resolution Model for Task-Oriented Dialogue",
    author = "Quan, Jun  and
      Xiong, Deyi  and
      Webber, Bonnie  and
      Hu, Changjian",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "4547--4557",
    abstract = "Ellipsis and co-reference are common and ubiquitous especially in multi-turn dialogues. In this paper, we treat the resolution of ellipsis and co-reference in dialogue as a problem of generating omitted or referred expressions from the dialogue context. We therefore propose a unified end-to-end Generative Ellipsis and CO-reference Resolution model (GECOR) in the context of dialogue. The model can generate a new pragmatically complete user utterance by alternating the generation and copy mode for each user utterance. A multi-task learning framework is further proposed to integrate the GECOR into an end-to-end task-oriented dialogue. In order to train both the GECOR and the multi-task learning framework, we manually construct a new dataset on the basis of the public dataset CamRest676 with both ellipsis and co-reference annotation. On this dataset, intrinsic evaluations on the resolution of ellipsis and co-reference show that the GECOR model significantly outperforms the sequence-to-sequence (seq2seq) baseline model in terms of EM, BLEU and F1 while extrinsic evaluations on the downstream dialogue task demonstrate that our multi-task learning framework with GECOR achieves a higher success rate of task completion than TSCP, a state-of-the-art end-to-end task-oriented dialogue model.",
}

@inproceedings{davidson-etal-2019-dependency,
    title = "Dependency Parsing for Spoken Dialog Systems",
    author = "Davidson, Sam  and
      Yu, Dian  and
      Yu, Zhou",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "1513--1519",
    abstract = "Dependency parsing of conversational input can play an important role in language understanding for dialog systems by identifying the relationships between entities extracted from user utterances. Additionally, effective dependency parsing can elucidate differences in language structure and usage for discourse analysis of human-human versus human-machine dialogs. However, models trained on datasets based on news articles and web data do not perform well on spoken human-machine dialog, and currently available annotation schemes do not adapt well to dialog data. Therefore, we propose the Spoken Conversation Universal Dependencies (SCUD) annotation scheme that extends the Universal Dependencies (UD) (Nivre et al., 2016) guidelines to spoken human-machine dialogs. We also provide ConvBank, a conversation dataset between humans and an open-domain conversational dialog system with SCUD annotation. Finally, to demonstrate the utility of the dataset, we train a dependency parser on the ConvBank dataset. We demonstrate that by pre-training a dependency parser on a set of larger public datasets and fine-tuning on ConvBank data, we achieved the best result, 85.05{\%} unlabeled and 77.82{\%} labeled attachment accuracy.",
}

@inproceedings{pasupat-etal-2019-span,
    title = "Span-based Hierarchical Semantic Parsing for Task-Oriented Dialog",
    author = "Pasupat, Panupong  and
      Gupta, Sonal  and
      Mandyam, Karishma  and
      Shah, Rushin  and
      Lewis, Mike  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "1520--1526",
    abstract = "We propose a semantic parser for parsing compositional utterances into Task Oriented Parse (TOP), a tree representation that has intents and slots as labels of nesting tree nodes. Our parser is span-based: it scores labels of the tree nodes covering each token span independently, but then decodes a valid tree globally. In contrast to previous sequence decoding approaches and other span-based parsers, we (1) improve the training speed by removing the need to run the decoder at training time; and (2) introduce edge scores, which model relations between parent and child labels, to mitigate the independence assumption between node labels and improve accuracy. Our best parser outperforms previous methods on the TOP dataset of mixed-domain task-oriented utterances in both accuracy and training speed.",
}

@inproceedings{gupta-etal-2018-semantic,
    title = "Semantic Parsing for Task Oriented Dialog using Hierarchical Representations",
    author = "Gupta, Sonal  and
      Shah, Rushin  and
      Mohit, Mrinal  and
      Kumar, Anuj  and
      Lewis, Mike",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "2787--2792",
}

@article{bobrow-1977-gus,
author = {Bobrow, Daniel G. and Kaplan, Ronald M. and Kay, Martin and Norman, Donald A. and Thompson, Henry and Winograd, Terry},
title = {GUS, a Frame-Driven Dialog System},
year = {1977},
issue_date = {April 1977},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {8},
number = {2},
issn = {0004-3702},
journal = {Artif. Intell.},
month = apr,
pages = {155173},
numpages = {19}
}

@article{bohus2009ravenclaw,
  title={The RavenClaw dialog management framework: Architecture and systems},
  author={Bohus, Dan and Rudnicky, Alexander I},
  journal={Computer Speech \& Language},
  volume={23},
  number={3},
  pages={332--361},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{stent-2000-rhetorical,
    title = "Rhetorical Structure in Dialog",
    author = "Stent, Amanda",
    booktitle = "{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation",
    month = jun,
    year = "2000",
    address = "Mitzpe Ramon, Israel",
    publisher = "Association for Computational Linguistics",
    pages = "247--252",
}

@InProceedings{elasri2017frames,
author = {El Asri, Layla and Schulz, Hannes and Sharma, Shikhar and Zumer, Jeremie and Harris, Justin D. and Fine, Emery and Mehrotra, Rahul and Suleman, Kaheer},
title = {Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems},
booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
year = {2017},
month = {August},
abstract = {This paper proposes a new dataset, Frames, composed of 1369 human-human dialogues with an average of 15 turns per dialogue. This corpus contains goal-oriented dialogues between users who are given some constraints to book a trip and assistants who search a database to find appropriate trips. The users exhibit complex decision-making behaviour which involve comparing trips, exploring different options, and selecting among the trips that were discussed during the dialogue. To drive research on dialogue systems towards handling such behaviour, we have annotated and released the dataset and we propose in this paper a task called frame tracking. This task consists of keeping track of different semantic frames throughout each dialogue. We propose a rule-based baseline and analyse the frame tracking task through this baseline.},
publisher = {Association for Computational Linguistics},
pages = {207-219},
edition = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
}

@book{meteer1995dysfluency,
  title={Dysfluency annotation stylebook for the switchboard corpus},
  author={Meteer, Marie W and Taylor, Ann A and MacIntyre, Robert and Iyer, Rukmini},
  year={1995},
  publisher={University of Pennsylvania Philadelphia, PA}
}

@inproceedings{dusek-jurcicek-2016-sequence,
    title = "Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings",
    author = "Du{\v{s}}ek, Ond{\v{r}}ej  and
      Jur{\v{c}}{\'\i}{\v{c}}ek, Filip",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    pages = "45--51",
}

@article{silva2011symbolic,
  title={From symbolic to sub-symbolic information in question classification},
  author={Silva, Joao and Coheur, Lu{\'\i}sa and Mendes, Ana Cristina and Wichert, Andreas},
  journal={Artificial Intelligence Review},
  volume={35},
  number={2},
  pages={137--154},
  year={2011},
  publisher={Springer}
}

@inproceedings{hashemi2016query,
  title={Query intent detection using convolutional neural networks},
  author={Hashemi, Homa B and Asiaee, Amir and Kraft, Reiner},
  booktitle={International Conference on Web Search and Data Mining, Workshop on Query Understanding},
  year={2016}
}

@inproceedings{shi-etal-2016-deep,
    title = "Deep {LSTM} based Feature Mapping for Query Classification",
    author = "Shi, Yangyang  and
      Yao, Kaisheng  and
      Tian, Le  and
      Jiang, Daxin",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    pages = "1501--1511",
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    pages = "311--318",
}

@InProceedings{liu2016,
  author =  "Liu, Chia-Wei
    and Lowe, Ryan
    and Serban, Iulian
    and Noseworthy, Mike
    and Charlin, Laurent
    and Pineau, Joelle",
  title =   "How NOT To Evaluate Your Dialogue System: An Empirical Study of      Unsupervised Evaluation Metrics for Dialogue Response Generation    ",
  booktitle =   "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
  year =  "2016",
  publisher =   "Association for Computational Linguistics",
  pages =   "2122--2132",
  location =  "Austin, Texas",
}

@inproceedings{takanobu-etal-2020-goal,
    title = "Is Your Goal-Oriented Dialog Model Performing Really Well? Empirical Analysis of System-wise Evaluation",
    author = "Takanobu, Ryuichi  and
      Zhu, Qi  and
      Li, Jinchao  and
      Peng, Baolin  and
      Gao, Jianfeng  and
      Huang, Minlie",
    booktitle = "Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = jul,
    year = "2020",
    address = "1st virtual meeting",
    publisher = "Association for Computational Linguistics",
    pages = "297--310",
    abstract = "There is a growing interest in developing goal-oriented dialog systems which serve users in accomplishing complex tasks through multi-turn conversations. Although many methods are devised to evaluate and improve the performance of individual dialog components, there is a lack of comprehensive empirical study on how different components contribute to the overall performance of a dialog system. In this paper, we perform a system-wise evaluation and present an empirical analysis on different types of dialog systems which are composed of different modules in different settings. Our results show that (1) a pipeline dialog system trained using fine-grained supervision signals at different component levels often obtains better performance than the systems that use joint or end-to-end models trained on coarse-grained labels, (2) component-wise, single-turn evaluation results are not always consistent with the overall performance of a dialog system, and (3) despite the discrepancy between simulators and human users, simulated evaluation is still a valid alternative to the costly human evaluation especially in the early stage of development.",
}

@InProceedings{novikova2017,
  author =  "Novikova, Jekaterina
    and Du{\v{s}}ek, Ond{\v{r}}ej
    and Cercas Curry, Amanda
    and Rieser, Verena",
  title =   "Why We Need New Evaluation Metrics for {NLG}",
  booktitle =   "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
  year =  "2017",
  publisher =   "Association for Computational Linguistics",
  pages =   "2241--2252",
  location =  "Copenhagen, Denmark",
}

@inproceedings{mesnil2013investigation,
  title={Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding.},
  author={Mesnil, Gr{\'e}goire and He, Xiaodong and Deng, Li and Bengio, Yoshua},
  booktitle={Interspeech},
  pages={3771--3775},
  year={2013}
}

@article{liu2016attention,
  title={Attention-based recurrent neural network models for joint intent detection and slot filling},
  author={Liu, Bing and Lane, Ian},
  journal={arXiv preprint arXiv:1609.01454},
  year={2016}
}

@inproceedings{imamura2014predicate,
  title={Predicate-argument structure analysis with zero-anaphora resolution for dialogue systems},
  author={Imamura, Kenji and Higashinaka, Ryuichiro and Izumi, Tomoko},
  booktitle={Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers},
  pages={806--815},
  year={2014}
}

@inproceedings{yoshino2011spoken,
  title={Spoken dialogue system based on information extraction using similarity of predicate argument structures},
  author={Yoshino, Koichiro and Mori, Shinsuke and Kawahara, Tatsuya},
  booktitle={Proceedings of the SIGDIAL 2011 Conference},
  pages={59--66},
  year={2011},
  organization={Association for Computational Linguistics}
}

@techreport{traum1994computational,
  title={A Computational Theory of Grounding in Natural Language Conversation.},
  author={Traum, David R},
  year={1994},
  institution={ROCHESTER UNIV NY DEPT OF COMPUTER SCIENCE}
}

@article{williams2016dialog,
  title={The dialog state tracking challenge series: A review},
  author={Williams, Jason and Raux, Antoine and Henderson, Matthew},
  journal={Dialogue \& Discourse},
  volume={7},
  number={3},
  pages={4--33},
  year={2016}
}

@incollection{talmy1983language,
  title={How language structures space},
  author={Talmy, Leonard},
  booktitle={Spatial orientation},
  pages={225--282},
  year={1983},
  publisher={Springer}
}

@inproceedings{platonov2018computational,
  title={Computational models for spatial prepositions},
  author={Platonov, Georgiy and Schubert, Lenhart},
  booktitle={Proceedings of the First International Workshop on Spatial Language Understanding},
  pages={21--30},
  year={2018}
}

@inproceedings{ramisa-etal-2015-combining,
    title = "Combining Geometric, Textual and Visual Features for Predicting Prepositions in Image Descriptions",
    author = "Ramisa, Arnau  and
      Wang, Josiah  and
      Lu, Ying  and
      Dellandrea, Emmanuel  and
      Moreno-Noguer, Francesc  and
      Gaizauskas, Robert",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    pages = "214--220",
}

@inproceedings{ghanimifard2019neural,
  title={What a neural language model tells us about spatial relations},
  author={Ghanimifard, Mehdi and Dobnik, Simon},
  booktitle={Proceedings of the Combined Workshop on Spatial Language Understanding (SpLU) and Grounded Communication for Robotics (RoboNLP)},
  pages={71--81},
  year={2019}
}

@InProceedings{cho2014properties,
  author =  "Cho, Kyunghyun
    and van Merrienboer, Bart
    and Bahdanau, Dzmitry
    and Bengio, Yoshua",
  title =   "On the Properties of Neural Machine Translation: Encoder--Decoder Approaches",
  booktitle =   "Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation",
  year =  "2014",
  publisher =   "Association for Computational Linguistics",
  pages =   "103--111",
  location =  "Doha, Qatar",
}

@Article{monroe2017colors,
  author =  "Monroe, Will
    and Hawkins, Robert X. D.
    and Goodman, Noah D.
    and Potts, Christopher",
  title =   "Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding",
  journal =   "Transactions of the Association for Computational Linguistics",
  year =  "2017",
  volume =  "5",
  pages =   "325--338",
}

@inproceedings{potts2012goal,
  title={Goal-driven answers in the Cards dialogue corpus},
  author={Potts, Christopher},
  booktitle={Proceedings of the 30th west coast conference on formal linguistics},
  pages={1--20},
  year={2012},
  organization={Cascadilla Proceedings Project}
}

@book{austin1962things,
  title={How to do things with words},
  author={Austin, John Langshaw},
  year={1962},
  publisher={Oxford university press}
}

@inproceedings{Kingma2015AdamAM,
  title={Adam: {A} Method for Stochastic Optimization},
  author={Kingma, Diederik P. and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{takmaz-etal-2020-refer,
    title = "{R}efer, Reuse, Reduce: {G}enerating Subsequent References in Visual and Conversational Contexts",
    author = "Takmaz, Ece  and
      Giulianelli, Mario  and
      Pezzelle, Sandro  and
      Sinclair, Arabella  and
      Fern{\'a}ndez, Raquel",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
    year = "2020",
    pages = "4350--4368",
}

@book{searle1969speech,
  title={Speech acts: An essay in the philosophy of language},
  author={Searle, John R},
  volume={626},
  year={1969},
  publisher={Cambridge university press}
}

@inproceedings{santoro2017simple,
  title={A simple neural network module for relational reasoning},
  author={Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
  booktitle={Advances in neural information processing systems},
  pages={4967--4976},
  year={2017}
}

@article{landau2017update,
  title={Update on what and where in spatial language: A new division of labor for spatial terms},
  author={Landau, Barbara},
  journal={Cognitive science},
  volume={41},
  pages={321--350},
  year={2017},
  publisher={Wiley Online Library}
}

@article{sugawara2019assessing,
  title={Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets},
  author={Sugawara, Saku and Stenetorp, Pontus and Inui, Kentaro and Aizawa, Akiko},
  journal={arXiv preprint arXiv:1911.09241},
  year={2019}
}

@inproceedings{sugawara-etal-2018-makes,
    title = "What Makes Reading Comprehension Questions Easier?",
    author = "Sugawara, Saku  and
      Inui, Kentaro  and
      Sekine, Satoshi  and
      Aizawa, Akiko",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "4208--4219",
    abstract = "A challenge in creating a dataset for machine reading comprehension (MRC) is to collect questions that require a sophisticated understanding of language to answer beyond using superficial cues. In this work, we investigate what makes questions easier across recent 12 MRC datasets with three question styles (answer extraction, description, and multiple choice). We propose to employ simple heuristics to split each dataset into easy and hard subsets and examine the performance of two baseline models for each of the subsets. We then manually annotate questions sampled from each subset with both validity and requisite reasoning skills to investigate which skills explain the difference between easy and hard questions. From this study, we observed that (i) the baseline performances for the hard subsets remarkably degrade compared to those of entire datasets, (ii) hard questions require knowledge inference and multiple-sentence reasoning in comparison with easy questions, and (iii) multiple-choice questions tend to require a broader range of reasoning skills than answer extraction and description questions. These results suggest that one might overestimate recent advances in MRC.",
}

@inproceedings{mccoy-etal-2019-right,
    title = "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference",
    author = "McCoy, Tom  and
      Pavlick, Ellie  and
      Linzen, Tal",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "3428--3448",
    abstract = "A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.",
}

@inproceedings{pang2020visual,
  title={Visual Dialogue State Tracking for Question Generation},
  author={Pang, Wei and Wang, Xiaojie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={11831--11838},
  year={2020}
}

@inproceedings{yu-etal-2019-see,
    title = "What You See is What You Get: Visual Pronoun Coreference Resolution in Dialogues",
    author = "Yu, Xintong  and
      Zhang, Hongming  and
      Song, Yangqiu  and
      Song, Yan  and
      Zhang, Changshui",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "5123--5132",
    abstract = "Grounding a pronoun to a visual object it refers to requires complex reasoning from various information sources, especially in conversational scenarios. For example, when people in a conversation talk about something all speakers can see, they often directly use pronouns (e.g., it) to refer to it without previous introduction. This fact brings a huge challenge for modern natural language understanding systems, particularly conventional context-based pronoun coreference models. To tackle this challenge, in this paper, we formally define the task of visual-aware pronoun coreference resolution (PCR) and introduce VisPro, a large-scale dialogue PCR dataset, to investigate whether and how the visual information can help resolve pronouns in dialogues. We then propose a novel visual-aware PCR model, VisCoref, for this task and conduct comprehensive experiments and case studies on our dataset. Results demonstrate the importance of the visual information in this PCR case and show the effectiveness of the proposed model.",
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6700--6709},
  year={2019}
}

@article{bahdanau2014nmt,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{huang2015bidirectional,
  title={Bidirectional LSTM-CRF Models for Sequence Tagging},
  author={Zhiheng Huang and Wei Xu and Kai Yu},
  journal={CoRR},
  year={2015},
  volume={abs/1508.01991},
}

@inproceedings{xu2015show,
  title={Show, attend and tell: {N}eural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={2048--2057},
  year={2015},
}

@article{de2018talk,
  title={Talk the walk: Navigating new york city through grounded dialogue},
  author={de Vries, Harm and Shuster, Kurt and Batra, Dhruv and Parikh, Devi and Weston, Jason and Kiela, Douwe},
  journal={arXiv preprint arXiv:1807.03367},
  year={2018}
}

@article{landau1993and,
  title={What and where in spatial language and spatial cognition},
  author={Landau, Barbara and Jackendoff, Ray},
  journal={Behavioral and brain sciences},
  volume={16},
  number={2},
  pages={217--238},
  year={1993},
  publisher={Cambridge University Press}
}

@inproceedings{ning-etal-2018-multi,
    title = "A Multi-Axis Annotation Scheme for Event Temporal Relations",
    author = "Ning, Qiang  and
      Wu, Hao  and
      Roth, Dan",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    pages = "1318--1328",
    abstract = "Existing temporal relation (TempRel) annotation schemes often have low inter-annotator agreements (IAA) even between experts, suggesting that the current annotation task needs a better definition. This paper proposes a new multi-axis modeling to better capture the temporal structure of events. In addition, we identify that event end-points are a major source of confusion in annotation, so we also propose to annotate TempRels based on start-points only. A pilot expert annotation effort using the proposed scheme shows significant improvement in IAA from the conventional 60{'}s to 80{'}s (Cohen{'}s Kappa). This better-defined annotation scheme further enables the use of crowdsourcing to alleviate the labor intensity for each annotator. We hope that this work can foster more interesting studies towards event understanding.",
}

@article{pustejovsky2003timeml,
  title={TimeML: Robust specification of event and temporal expressions in text.},
  author={Pustejovsky, James and Castano, Jos{\'e} M and Ingria, Robert and Sauri, Roser and Gaizauskas, Robert J and Setzer, Andrea and Katz, Graham and Radev, Dragomir R},
  journal={New directions in question answering},
  volume={3},
  pages={28--34},
  year={2003},
  publisher={Stanford, USA}
}

@inproceedings{alamri2019audio,
  title={Audio visual scene-aware dialog},
  author={Alamri, Huda and Cartillier, Vincent and Das, Abhishek and Wang, Jue and Cherian, Anoop and Essa, Irfan and Batra, Dhruv and Marks, Tim K and Hori, Chiori and Anderson, Peter and others},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7558--7567},
  year={2019}
}

@inproceedings{shukla-etal-2019-ask,
    title = "What Should {I} Ask? Using Conversationally Informative Rewards for Goal-oriented Visual Dialog.",
    author = "Shukla, Pushkar  and
      Elmadjian, Carlos  and
      Sharan, Richika  and
      Kulkarni, Vivek  and
      Turk, Matthew  and
      Wang, William Yang",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "6442--6451",
    abstract = "The ability to engage in goal-oriented conversations has allowed humans to gain knowledge, reduce uncertainty, and perform tasks more efficiently. Artificial agents, however, are still far behind humans in having goal-driven conversations. In this work, we focus on the task of goal-oriented visual dialogue, aiming to automatically generate a series of questions about an image with a single objective. This task is challenging since these questions must not only be consistent with a strategy to achieve a goal, but also consider the contextual information in the image. We propose an end-to-end goal-oriented visual dialogue system, that combines reinforcement learning with regularized information gain. Unlike previous approaches that have been proposed for the task, our work is motivated by the Rational Speech Act framework, which models the process of human inquiry to reach a goal. We test the two versions of our model on the GuessWhat?! dataset, obtaining significant results that outperform the current state-of-the-art models in the task of generating questions to find an undisclosed object in an image.",
}

@book{asher2003logics,
  title={Logics of conversation},
  author={Asher, Nicholas and Asher, Nicholas Michael and Lascarides, Alex},
  year={2003},
  publisher={Cambridge University Press}
}

@article{lascarides2009agreement,
  title={Agreement, disputes and commitments in dialogue},
  author={Lascarides, Alex and Asher, Nicholas},
  journal={Journal of semantics},
  volume={26},
  number={2},
  pages={109--158},
  year={2009},
  publisher={Oxford University Press}
}

@article{kelleher-costello-2009-applying,
    title = "Applying Computational Models of Spatial Prepositions to Visually Situated Dialog",
    author = "Kelleher, John D.  and
      Costello, Fintan J.",
    journal = "Computational Linguistics",
    volume = "35",
    number = "2",
    year = "2009",
    pages = "271--306",
}

@inproceedings{narayan-chen-etal-2019-collaborative,
    title = "Collaborative Dialogue in {M}inecraft",
    author = "Narayan-Chen, Anjali  and
      Jayannavar, Prashant  and
      Hockenmaier, Julia",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "5405--5415",
    abstract = "We wish to develop interactive agents that can communicate with humans to collaboratively solve tasks in grounded scenarios. Since computer games allow us to simulate such tasks without the need for physical robots, we define a Minecraft-based collaborative building task in which one player (A, the Architect) is shown a target structure and needs to instruct the other player (B, the Builder) to build this structure. Both players interact via a chat interface. A can observe B but cannot place blocks. We present the Minecraft Dialogue Corpus, a collection of 509 conversations and game logs. As a first step towards our goal of developing fully interactive agents for this task, we consider the subtask of Architect utterance generation, and show how challenging it is.",
}

@inproceedings{gururangan-etal-2018-annotation,
    title = "Annotation Artifacts in Natural Language Inference Data",
    author = "Gururangan, Suchin  and
      Swayamdipta, Swabha  and
      Levy, Omer  and
      Schwartz, Roy  and
      Bowman, Samuel  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    pages = "107--112",
    abstract = "Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67{\%} of SNLI (Bowman et. al, 2015) and 53{\%} of MultiNLI (Williams et. al, 2017). Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.",
}

@inproceedings{geva-etal-2019-modeling,
    title = "Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets",
    author = "Geva, Mor  and
      Goldberg, Yoav  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "1161--1166",
    abstract = "Crowdsourcing has been the prevalent paradigm for creating natural language understanding datasets in recent years. A common crowdsourcing practice is to recruit a small number of high-quality workers, and have them massively generate examples. Having only a few workers generate the majority of examples raises concerns about data diversity, especially when workers freely generate sentences. In this paper, we perform a series of experiments showing these concerns are evident in three recent NLP datasets. We show that model performance improves when training with annotator identifiers as features, and that models are able to recognize the most productive annotators. Moreover, we show that often models do not generalize well to examples from annotators that did not contribute to the training set. Our findings suggest that annotator bias should be monitored during dataset creation, and that test set annotators should be disjoint from training set annotators.",
}

@book{Hernndez-Orallo:2017:MME:3110808,
 author = {Hernndez-Orallo, Jos},
 title = {The Measure of All Minds: Evaluating Natural and Artificial Intelligence},
 year = {2017},
 isbn = {1107153018, 9781107153011},
 edition = {1st},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
} 

@article{cohen1968weighted,
  title={Weighted kappa: nominal scale agreement provision for scaled disagreement or partial credit.},
  author={Cohen, Jacob},
  journal={Psychological bulletin},
  volume={70},
  number={4},
  pages={213},
  year={1968},
  publisher={American Psychological Association}
}

@inproceedings{cirik-etal-2018-visual,
    title = "Visual Referring Expression Recognition: What Do Systems Actually Learn?",
    author = "Cirik, Volkan  and
      Morency, Louis-Philippe  and
      Berg-Kirkpatrick, Taylor",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    pages = "781--787",
    abstract = "We present an empirical analysis of state-of-the-art systems for referring expression recognition {--} the task of identifying the object in an image referred to by a natural language expression {--} with the goal of gaining insight into how these systems reason about language and vision. Surprisingly, we find strong evidence that even sophisticated and linguistically-motivated models for this task may ignore linguistic structure, instead relying on shallow correlations introduced by unintended biases in the data selection and annotation process. For example, we show that a system trained and tested on the input image without the input referring expression can achieve a precision of 71.2{\%} in top-2 predictions. Furthermore, a system that predicts only the object category given the input can achieve a precision of 84.2{\%} in top-2 predictions. These surprisingly positive results for what should be deficient prediction scenarios suggest that careful analysis of what our models are learning {--} and further, how our data is constructed {--} is critical as we seek to make substantive progress on grounded language tasks.",
}

@inproceedings{agarwal-etal-2020-history,
    title = "History for Visual Dialog: Do we really need it?",
    author = "Agarwal, Shubham  and
      Bui, Trung  and
      Lee, Joon-Young  and
      Konstas, Ioannis  and
      Rieser, Verena",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "8182--8197",
    abstract = "Visual Dialogue involves {``}understanding{''} the dialogue history (what has been discussed previously) and the current question (what is asked), in addition to grounding information in the image, to accurately generate the correct response. In this paper, we show that co-attention models which explicitly encode dialoh history outperform models that don{'}t, achieving state-of-the-art performance (72 {\%} NDCG on val set). However, we also expose shortcomings of the crowdsourcing dataset collection procedure, by showing that dialogue history is indeed only required for a small amount of the data, and that the current evaluation metric encourages generic replies. To that end, we propose a challenging subset (VisdialConv) of the VisdialVal set and the benchmark NDCG of 63{\%}.",
}

@inproceedings{ribeiro-etal-2020-beyond,
    title = "Beyond Accuracy: Behavioral Testing of {NLP} Models with {C}heck{L}ist",
    author = "Ribeiro, Marco Tulio  and
      Wu, Tongshuang  and
      Guestrin, Carlos  and
      Singh, Sameer",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "4902--4912",
    abstract = "Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.",
}

@article{gardner2020evaluating,
  title={Evaluating nlp models via contrast sets},
  author={Gardner, Matt and Artzi, Yoav and Basmova, Victoria and Berant, Jonathan and Bogin, Ben and Chen, Sihao and Dasigi, Pradeep and Dua, Dheeru and Elazar, Yanai and Gottumukkala, Ananth and others},
  journal={arXiv preprint arXiv:2004.02709},
  year={2020}
}

@article{kaushik2019learning,
  title={Learning the Difference that Makes a Difference with Counterfactually-Augmented Data},
  author={Kaushik, Divyansh and Hovy, Eduard and Lipton, Zachary C},
  journal={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{turing1950computing,
  added-at = {2012-06-19T15:53:23.000+0200},
  author = {Turing, A. M.},
  copyright = {Copyright  1950 Oxford University Press},
  interhash = {3f7a151a4f79fe75b4bb148b41279a9b},
  intrahash = {c6b8db241dec2cec3477ce771abebb8f},
  issn = {00264423},
  journal = {Mind},
  jstor_articletype = {research-article},
  jstor_formatteddate = {Oct., 1950},
  keywords = {},
  language = {English},
  number = 236,
  pages = {433--460},
  publisher = {Oxford University Press on behalf of the Mind Association},
  series = {New Series},
  timestamp = {2012-06-19T15:53:23.000+0200},
  title = {Computing Machinery and Intelligence},
  volume = 59,
  year = 1950
}

@book{wittgenstein1953philosophical,
  author = {Wittgenstein, Ludwig},
  publisher = {Basil Blackwell},
  title = {Philosophical Investigations},
  year = 1953
}

@book{tomasello2009constructing,
  title={Constructing a language},
  author={Tomasello, Michael},
  year={2009},
  publisher={Harvard university press}
}

@InProceedings{he2017learning,
  author =  "He, He
    and Balakrishnan, Anusha
    and Eric, Mihail
    and Liang, Percy",
  title =   "Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge      Graph Embeddings    ",
  booktitle =   "Proceedings of the 55th Annual Meeting of the Association for      Computational Linguistics (Volume 1: Long Papers)    ",
  year =  "2017",
  publisher =   "Association for Computational Linguistics",
  pages =   "1766--1776",
  location =  "Vancouver, Canada",
}

@inproceedings{fang2015embodied,
 author = {Fang, Rui and Doering, Malcolm and Chai, Joyce Y.},
 title = {Embodied Collaborative Referring Expression Generation in Situated Human-Robot Interaction},
 booktitle = {Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction},
 series = {HRI '15},
 year = {2015},
 isbn = {978-1-4503-2883-8},
 location = {Portland, Oregon, USA},
 pages = {271--278},
 numpages = {8},
 acmid = {2696467},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative model, human-robot dialogue, referring expression generation},
} 

@article{dafoe2020open,
  title={Open Problems in Cooperative AI},
  author={Dafoe, Allan and Hughes, Edward and Bachrach, Yoram and Collins, Tantum and McKee, Kevin R and Leibo, Joel Z and Larson, Kate and Graepel, Thore},
  journal={arXiv preprint arXiv:2012.08630},
  year={2020}
}

@inproceedings{girdhar2020cater,
    title = {{CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning}},
    author = {Girdhar, Rohit and Ramanan, Deva},
    booktitle = {ICLR},
    year = 2020
}

@inproceedings{clark1991grounding,
  title={Grounding in communication},
  author={H. Clark and Susan E. Brennan},
  booktitle={Perspectives on socially shared cognition},
  year={1991}
}

@incollection{brennan2010two,
  title={Two minds, one dialog: Coordinating speaking and understanding},
  author={Brennan, Susan E and Galati, Alexia and Kuhlen, Anna K},
  booktitle={Psychology of learning and motivation},
  volume={53},
  pages={301--344},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{chai2018language,
  title={Language to Action: Towards Interactive Task Learning with Physical Agents.},
  author={Chai, Joyce Y and Gao, Qiaozi and She, Lanbo and Yang, Shaohua and Saba-Sadiya, Sari and Xu, Guangyue},
  booktitle={IJCAI},
  pages={2--9},
  year={2018}
}

@book{tomasello2010origins,
  title={Origins of human communication},
  author={Tomasello, Michael},
  year={2010},
  publisher={MIT press}
}

@inproceedings{huang-buch-2018-finding-it,
  title={Finding ``It'': Weakly-Supervised, Reference-Aware Visual Grounding in Instructional Videos},
  author={De-An Huang* and Shyamal Buch* and Lucio Dery and Animesh Garg and Li Fei-Fei and Juan Carlos Niebles},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@InProceedings{Maeoki_2020_CVPR_Workshops,
author = {Maeoki, Sho and Uehara, Kohei and Harada, Tatsuya},
title = {Interactive Video Retrieval With Dialog},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020}
}

@inproceedings{bakhtin2019phyre,
 author = {Bakhtin, Anton and van der Maaten, Laurens and Johnson, Justin and Gustafson, Laura and Girshick, Ross},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {5082--5093},
 publisher = {Curran Associates, Inc.},
 title = {PHYRE: A New Benchmark for Physical Reasoning},
 volume = {32},
 year = {2019}
}

@article{hossain2019comprehensive,
  title={A comprehensive survey of deep learning for image captioning},
  author={Hossain, MD Zakir and Sohel, Ferdous and Shiratuddin, Mohd Fairuz and Laga, Hamid},
  journal={ACM Computing Surveys (CsUR)},
  volume={51},
  number={6},
  pages={1--36},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{aafaq2019video,
author = {Aafaq, Nayyer and Mian, Ajmal and Liu, Wei and Gilani, Syed Zulqarnain and Shah, Mubarak},
title = {Video Description: A Survey of Methods, Datasets, and Evaluation Metrics},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
abstract = {Video description is the automatic generation of natural language sentences that describe the contents of a given video. It has applications in human-robot interaction, helping the visually impaired and video subtitling. The past few years have seen a surge of research in this area due to the unprecedented success of deep learning in computer vision and natural language processing. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, calling the need for a comprehensive survey to focus research efforts in this flourishing new direction. This article fills the gap by surveying the state-of-the-art approaches with a focus on deep learning models; comparing benchmark datasets in terms of their domains, number of classes, and repository size; and identifying the pros and cons of various evaluation metrics, such as SPICE, CIDEr, ROUGE, BLEU, METEOR, and WMD. Classical video description approaches combined subject, object, and verb detection with template-based language models to generate sentences. However, the release of large datasets revealed that these methods cannot cope with the diversity in unconstrained open domain videos. Classical approaches were followed by a very short era of statistical methods that were soon replaced with deep learning, the current state-of-the-art in video description. Our survey shows that despite the fast-paced developments, video description research is still in its infancy due to the following reasons: Analysis of video description models is challenging, because it is difficult to ascertain the contributions towards accuracy or errors of the visual features and the adopted language model in the final description. Existing datasets neither contain adequate visual diversity nor complexity of linguistic structures. Finally, current evaluation metrics fall short of measuring the agreement between machine-generated descriptions with that of humans. We conclude our survey by listing promising future research directions.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {115},
numpages = {37},
keywords = {Video description, video to text, language in vision, video captioning}
}

@inproceedings{deriu-etal-2020-spot,
    title = "Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems",
    author = {Deriu, Jan  and
      Tuggener, Don  and
      von D{\"a}niken, Pius  and
      Campos, Jon Ander  and
      Rodrigo, Alvaro  and
      Belkacem, Thiziri  and
      Soroa, Aitor  and
      Agirre, Eneko  and
      Cieliebak, Mark},
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "3971--3984",
    abstract = "The lack of time efficient and reliable evalu-ation methods is hampering the development of conversational dialogue systems (chat bots). Evaluations that require humans to converse with chat bots are time and cost intensive, put high cognitive demands on the human judges, and tend to yield low quality results. In this work, we introduce Spot The Bot, a cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots. Human judges then only annotate for each entity in a conversation whether they think it is human or not (assuming there are humans participants in these conversations). These annotations then allow us to rank chat bots regarding their ability to mimic conversational behaviour of humans. Since we expect that all bots are eventually recognized as such, we incorporate a metric that measures which chat bot is able to uphold human-like be-havior the longest, i.e.Survival Analysis. This metric has the ability to correlate a bot{'}s performance to certain of its characteristics (e.g.fluency or sensibleness), yielding interpretable results. The comparably low cost of our frame-work allows for frequent evaluations of chatbots during their evaluation cycle. We empirically validate our claims by applying Spot The Bot to three domains, evaluating several state-of-the-art chat bots, and drawing comparisonsto related work. The framework is released asa ready-to-use tool.",
}

@article{Steels2005coordinatingPG,
  title={coordinating perceptually grounded categories through language: a case study for colour},
  author={L. Steels and Tony Belpaeme},
  journal={Behavioral and Brain Sciences},
  year={2005},
  volume={28},
  pages={469--489}
}

@article{lewis1969convention,
  title={Convention Cambridge},
  author={Lewis, David},
  journal={Mass.: Harvard UP},
  year={1969}
}

@article{clark1989contributing,
  title={Contributing to discourse},
  author={Clark, Herbert H and Schaefer, Edward F},
  journal={Cognitive science},
  volume={13},
  number={2},
  pages={259--294},
  year={1989},
  publisher={Wiley Online Library}
}

@book{van2007dynamic,
  title={Dynamic epistemic logic},
  author={Van Ditmarsch, Hans and van Der Hoek, Wiebe and Kooi, Barteld},
  volume={337},
  year={2007},
  publisher={Springer Science \& Business Media}
}

@article{schlangen2019grounded,
  title={Grounded Agreement Games: Emphasizing Conversational Grounding in Visual Dialogue Settings},
  author={Schlangen, David},
  journal={arXiv preprint arXiv:1908.11279},
  year={2019}
}

@inproceedings{pasunuru-bansal-2018-game,
    title = "Game-Based Video-Context Dialogue",
    author = "Pasunuru, Ramakanth  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "125--136",
    abstract = "Current dialogue systems focus more on textual and speech context knowledge and are usually based on two speakers. Some recent work has investigated static image-based dialogue. However, several real-world human interactions also involve dynamic visual context (similar to videos) as well as dialogue exchanges among multiple speakers. To move closer towards such multimodal conversational skills and visually-situated applications, we introduce a new video-context, many-speaker dialogue dataset based on live-broadcast soccer game videos and chats from Twitch.tv. This challenging testbed allows us to develop visually-grounded dialogue models that should generate relevant temporal and spatial event language from the live video, while also being relevant to the chat history. For strong baselines, we also present several discriminative and generative models, e.g., based on tridirectional attention flow (TriDAF). We evaluate these models via retrieval ranking-recall, automatic phrase-matching metrics, as well as human evaluation studies. We also present dataset analyses, model ablations, and visualizations to understand the contribution of different modalities and model components.",
}

@inproceedings{sai2019re,
  title={Re-evaluating adem: A deeper look at scoring dialogue responses},
  author={Sai, Ananya B and Gupta, Mithun Das and Khapra, Mitesh M and Srinivasan, Mukundhan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={6220--6227},
  year={2019}
}

@inproceedings{lowe-etal-2017-towards,
    title = "Towards an Automatic {T}uring Test: Learning to Evaluate Dialogue Responses",
    author = "Lowe, Ryan  and
      Noseworthy, Michael  and
      Serban, Iulian Vlad  and
      Angelard-Gontier, Nicolas  and
      Bengio, Yoshua  and
      Pineau, Joelle",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "1116--1126",
    abstract = "Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with human judgements of response quality (Liu et al., 2016). Yet having an accurate automatic evaluation procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new models with fewer expensive human evaluations. In response to this challenge, we formulate automatic dialogue evaluation as a learning problem.We present an evaluation model (ADEM)that learns to predict human-like scores to input responses, using a new dataset of human response scores. We show that the ADEM model{'}s predictions correlate significantly, and at a level much higher than word-overlap metrics such as BLEU, with human judgements at both the utterance and system-level. We also show that ADEM can generalize to evaluating dialogue mod-els unseen during training, an important step for automatic dialogue evaluation.",
}

@inproceedings{jayannavar-etal-2020-learning,
    title = "Learning to execute instructions in a {M}inecraft dialogue",
    author = "Jayannavar, Prashant  and
      Narayan-Chen, Anjali  and
      Hockenmaier, Julia",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "2589--2602",
    abstract = "The Minecraft Collaborative Building Task is a two-player game in which an Architect (A) instructs a Builder (B) to construct a target structure in a simulated Blocks World Environment. We define the subtask of predicting correct action sequences (block placements and removals) in a given game context, and show that capturing B{'}s past actions as well as B{'}s perspective leads to a significant improvement in performance on this challenging language understanding problem.",
}

@inproceedings{urbanek-etal-2019-learning,
    title = "Learning to Speak and Act in a Fantasy Text Adventure Game",
    author = {Urbanek, Jack  and
      Fan, Angela  and
      Karamcheti, Siddharth  and
      Jain, Saachi  and
      Humeau, Samuel  and
      Dinan, Emily  and
      Rockt{\"a}schel, Tim  and
      Kiela, Douwe  and
      Szlam, Arthur  and
      Weston, Jason},
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "673--683",
    abstract = "We introduce a large-scale crowdsourced text adventure game as a research platform for studying grounded dialogue. In it, agents can perceive, emote, and act whilst conducting dialogue with other agents. Models and humans can both act as characters within the game. We describe the results of training state-of-the-art generative and retrieval models in this setting. We show that in addition to using past dialogue, these models are able to effectively use the state of the underlying world to condition their predictions. In particular, we show that grounding on the details of the local environment, including location descriptions, and the objects (and their affordances) and characters (and their previous actions) present within it allows better predictions of agent behavior and dialogue. We analyze the ingredients necessary for successful grounding in this setting, and how each of these factors relate to agents that can talk and act successfully.",
}

@inproceedings{moon-etal-2020-situated,
    title = "Situated and Interactive Multimodal Conversations",
    author = "Moon, Seungwhan  and
      Kottur, Satwik  and
      Crook, Paul  and
      De, Ankita  and
      Poddar, Shivani  and
      Levin, Theodore  and
      Whitney, David  and
      Difranco, Daniel  and
      Beirami, Ahmad  and
      Cho, Eunjoon  and
      Subba, Rajen  and
      Geramifard, Alborz",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    pages = "1103--1121",
    abstract = "Next generation virtual assistants are envisioned to handle multimodal inputs (e.g., vision, memories of previous interactions, and the user{'}s utterances), and perform multimodal actions (, displaying a route while generating the system{'}s utterance). We introduce Situated Interactive MultiModal Conversations (SIMMC) as a new direction aimed at training agents that take multimodal actions grounded in a co-evolving multimodal input context in addition to the dialog history. We provide two SIMMC datasets totalling {\textasciitilde}13K human-human dialogs ({\textasciitilde}169K utterances) collected using a multimodal Wizard-of-Oz (WoZ) setup, on two shopping domains: (a) furniture {--} grounded in a shared virtual environment; and (b) fashion {--} grounded in an evolving set of images. Datasets include multimodal context of the items appearing in each scene, and contextual NLU, NLG and coreference annotations using a novel and unified framework of SIMMC conversational acts for both user and assistant utterances. Finally, we present several tasks within SIMMC as objective evaluation protocols, such as structural API prediction, response generation, and dialog state tracking. We benchmark a collection of existing models on these SIMMC tasks as strong baselines, and demonstrate rich multimodal conversational interactions. Our data, annotations, and models will be made publicly available.",
}

@inproceedings{thomason:corl19,
  title={Vision-and-Dialog Navigation},
  author={Jesse Thomason and Michael Murray and Maya Cakmak and Luke Zettlemoyer},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2019}
}

@InProceedings{Sadhu_2020_CVPR,
  author = {Sadhu, Arka and Chen, Kan and Nevatia, Ram},
  title = {Video Object Grounding using Semantic Roles in Language Description},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2020}
}

@InProceedings{antol2015vqa,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {{VQA}: {V}isual {Q}uestion {A}nswering},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2015},
}

@inproceedings{lei-etal-2018-tvqa,
    title = "{TVQA}: Localized, Compositional Video Question Answering",
    author = "Lei, Jie  and
      Yu, Licheng  and
      Bansal, Mohit  and
      Berg, Tamara",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "1369--1379",
}

@inproceedings{lei-etal-2020-tvqa,
    title = "{TVQA}+: Spatio-Temporal Grounding for Video Question Answering",
    author = "Lei, Jie  and
      Yu, Licheng  and
      Berg, Tamara  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "8211--8225",
    abstract = "We present the task of Spatio-Temporal Video Question Answering, which requires intelligent systems to simultaneously retrieve relevant moments and detect referenced visual concepts (people and objects) to answer natural language questions about videos. We first augment the TVQA dataset with 310.8K bounding boxes, linking depicted objects to visual concepts in questions and answers. We name this augmented version as TVQA+. We then propose Spatio-Temporal Answerer with Grounded Evidence (STAGE), a unified framework that grounds evidence in both spatial and temporal domains to answer questions about videos. Comprehensive experiments and analyses demonstrate the effectiveness of our framework and how the rich annotations in our TVQA+ dataset can contribute to the question answering task. Moreover, by performing this joint task, our model is able to produce insightful and interpretable spatio-temporal attention visualizations.",
}

@article{firth1957synopsis,
  title={A synopsis of linguistic theory, 1930-1955},
  author={Firth, John R},
  journal={Studies in linguistic analysis},
  year={1957},
  publisher={Basil Blackwell}
}

@article{marcus-etal-1993-building,
    title = "Building a Large Annotated Corpus of {E}nglish: The {P}enn {T}reebank",
    author = "Marcus, Mitchell P.  and
      Santorini, Beatrice  and
      Marcinkiewicz, Mary Ann",
    journal = "Computational Linguistics",
    volume = "19",
    number = "2",
    year = "1993",
    pages = "313--330",
}

@inproceedings{bisk-etal-2020-experience,
    title = "Experience Grounds Language",
    author = "Bisk, Yonatan  and
      Holtzman, Ari  and
      Thomason, Jesse  and
      Andreas, Jacob  and
      Bengio, Yoshua  and
      Chai, Joyce  and
      Lapata, Mirella  and
      Lazaridou, Angeliki  and
      May, Jonathan  and
      Nisnevich, Aleksandr  and
      Pinto, Nicolas  and
      Turian, Joseph",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "8718--8735",
    abstract = "Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful. Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.",
}

@inproceedings{yu2019activityqa,
    author = {Yu, Zhou and Xu, Dejing and Yu, Jun and Yu, Ting and Zhao, Zhou and Zhuang, Yueting and Tao, Dacheng},
    title = {ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering},
    booktitle = {AAAI},
    pages = {9127--9134},
    year = {2019}
}

@inproceedings{castro-etal-2020-lifeqa,
    title = "{L}ife{QA}: A Real-life Dataset for Video Question Answering",
    author = "Castro, Santiago  and
      Azab, Mahmoud  and
      Stroud, Jonathan  and
      Noujaim, Cristina  and
      Wang, Ruoyao  and
      Deng, Jia  and
      Mihalcea, Rada",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    pages = "4352--4358",
    abstract = "We introduce LifeQA, a benchmark dataset for video question answering that focuses on day-to-day real-life situations. Current video question answering datasets consist of movies and TV shows. However, it is well-known that these visual domains are not representative of our day-to-day lives. Movies and TV shows, for example, benefit from professional camera movements, clean editing, crisp audio recordings, and scripted dialog between professional actors. While these domains provide a large amount of data for training models, their properties make them unsuitable for testing real-life question answering systems. Our dataset, by contrast, consists of video clips that represent only real-life scenarios. We collect 275 such video clips and over 2.3k multiple-choice questions. In this paper, we analyze the challenging but realistic aspects of LifeQA, and we apply several state-of-the-art video question answering models to provide benchmarks for future research. The full dataset is publicly available at https://lit.eecs.umich.edu/lifeqa/.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

  @inproceedings{ZhLoCoBMVC18,
    author={Zhou, Luowei and Louis, Nathan and Corso, Jason J},
    title={Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction},
    booktitle = {British Machine Vision Conference},
    year = {2018},
  }

  @inproceedings{chen-etal-2019-weakly,
    title = "Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video",
    author = "Chen, Zhenfang  and
      Ma, Lin  and
      Luo, Wenhan  and
      Wong, Kwan-Yee Kenneth",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "1884--1894",
    abstract = "In this paper, we address a novel task, namely weakly-supervised spatio-temporally grounding natural sentence in video. Specifically, given a natural sentence and a video, we localize a spatio-temporal tube in the video that semantically corresponds to the given sentence, with no reliance on any spatio-temporal annotations during training. First, a set of spatio-temporal tubes, referred to as instances, are extracted from the video. We then encode these instances and the sentence using our newly proposed attentive interactor which can exploit their fine-grained relationships to characterize their matching behaviors. Besides a ranking loss, a novel diversity loss is introduced to train our attentive interactor to strengthen the matching behaviors of reliable instance-sentence pairs and penalize the unreliable ones. We also contribute a dataset, called VID-sentence, based on the ImageNet video object detection dataset, to serve as a benchmark for our task. Results from extensive experiments demonstrate the superiority of our model over the baseline approaches.",
}

@inproceedings{krishna2017dense,
    title={Dense-Captioning Events in Videos},
    author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Niebles, Juan Carlos},
    booktitle={International Conference on Computer Vision (ICCV)},
    year={2017}
}

@inproceedings{zellers2018scenegraphs,
  title={Neural Motifs: Scene Graph Parsing with Global Context},
  author={Zellers, Rowan and Yatskar, Mark and Thomson, Sam and Choi, Yejin},
  booktitle = "Conference on Computer Vision and Pattern Recognition",  
  year={2018}
}

@inproceedings{johnson2015image,
  title={Image retrieval using scene graphs},
  author={Johnson, Justin and Krishna, Ranjay and Stark, Michael and Li, Li-Jia and Shamma, David and Bernstein, Michael and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3668--3678},
  year={2015}
}

@article{Sacks1974ASS,
  title={A simplest systematics for the organization of turn-taking for conversation},
  author={Harvey Sacks and E. Schegloff and G. Jefferson},
  journal={Language},
  year={1974},
  volume={50},
  pages={696-735}
}

@article{carpendale2004constructing,
  title={Constructing an understanding of mind: The development of children's social understanding within social interaction},
  author={Carpendale, Jeremy I and Lewis, Charlie},
  journal={Behavioral and brain sciences},
  volume={27},
  number={1},
  pages={79--96},
  year={2004}
}

@article{hendrix-1982-natural,
    title = "Natural-Language Interface",
    author = "Hendrix, Gary G.",
    journal = "American Journal of Computational Linguistics",
    volume = "8",
    number = "2",
    year = "1982",
    pages = "56--61",
}

@Book{GoodBengCour16,
  Title                    = {Deep Learning},
  Author                   = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
  Publisher                = {MIT Press},
  Year                     = {2016},
  Address                  = {Cambridge, MA, USA},
}

@inproceedings{henderson-etal-2014-second,
    title = "The Second Dialog State Tracking Challenge",
    author = "Henderson, Matthew  and
      Thomson, Blaise  and
      Williams, Jason D.",
    booktitle = "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL})",
    month = jun,
    year = "2014",
    address = "Philadelphia, PA, U.S.A.",
    publisher = "Association for Computational Linguistics",
    pages = "263--272",
}

@book{schegloff2007sequence,
  title={Sequence organization in interaction: A primer in conversation analysis I},
  author={Schegloff, Emanuel A},
  volume={1},
  year={2007},
  publisher={Cambridge university press}
}

@book{langacker1987foundations,
  title={Foundations of Cognitive Grammar},
  author={Langacker, Ronald W},
  year={1987},
  publisher={Stanford University Press}
}

@article{paradis_2008,
  title={Configurations, construals and change: expressions of {DEGREE}},
  volume={12},
  number={2},
  journal={English Language and Linguistics},
  publisher={Cambridge University Press},
  author={Paradis, Carita},
  year={2008},
  pages={317343}
}

@inproceedings{shore-etal-2018-kth,
    title = "{KTH} Tangrams: A Dataset for Research on Alignment and Conceptual Pacts in Task-Oriented Dialogue",
    author = "Shore, Todd  and
      Androulakaki, Theofronia  and
      Skantze, Gabriel",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
}

@article{weizenbaum1966eliza,
  title={ELIZAa computer program for the study of natural language communication between man and machine},
  author={Weizenbaum, Joseph},
  journal={Communications of the ACM},
  volume={9},
  number={1},
  pages={36--45},
  year={1966},
  publisher={ACM New York, NY, USA}
}

@inproceedings{roller-etal-2021-recipes,
    title = "Recipes for Building an Open-Domain Chatbot",
    author = "Roller, Stephen  and
      Dinan, Emily  and
      Goyal, Naman  and
      Ju, Da  and
      Williamson, Mary  and
      Liu, Yinhan  and
      Xu, Jing  and
      Ott, Myle  and
      Smith, Eric Michael  and
      Boureau, Y-Lan  and
      Weston, Jason",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "300--325",
    abstract = "Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we highlight other ingredients. Good conversation requires blended skills: providing engaging talking points, and displaying knowledge, empathy and personality appropriately, while maintaining a consistent persona. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter models, and make our models and code publicly available. Human evaluations show our best models outperform existing approaches in multi-turn dialogue on engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.",
}

@article{gao2019neural,
year = {2019},
volume = {13},
journal = {Foundations and Trends in Information Retrieval},
title = {Neural Approaches to Conversational AI},
issn = {1554-0669},
number = {2-3},
pages = {127-298},
author = {Jianfeng Gao and Michel Galley and Lihong Li}
}

@article{schegloff1977preference,
  title={The preference for self-correction in the organization of repair in conversation},
  author={Schegloff, Emanuel A and Jefferson, Gail and Sacks, Harvey},
  journal={Language},
  volume={53},
  number={2},
  pages={361--382},
  year={1977},
  publisher={Linguistic Society of America}
}

@article{adiwardana2020towards,
  title={Towards a human-like open-domain chatbot},
  author={Adiwardana, Daniel and Luong, Minh-Thang and So, David R and Hall, Jamie and Fiedel, Noah and Thoppilan, Romal and Yang, Zi and Kulshreshtha, Apoorv and Nemade, Gaurav and Lu, Yifeng and others},
  journal={arXiv preprint arXiv:2001.09977},
  year={2020}
}

@inproceedings{hakkani2016multi,
  title={Multi-domain joint semantic frame parsing using bi-directional rnn-lstm.},
  author={Hakkani-T{\"u}r, Dilek and T{\"u}r, G{\"o}khan and Celikyilmaz, Asli and Chen, Yun-Nung and Gao, Jianfeng and Deng, Li and Wang, Ye-Yi},
  booktitle={Interspeech},
  pages={715--719},
  year={2016}
}

@inproceedings{paun-etal-2018-probabilistic,
    title = "A Probabilistic Annotation Model for Crowdsourcing Coreference",
    author = "Paun, Silviu  and
      Chamberlain, Jon  and
      Kruschwitz, Udo  and
      Yu, Juntao  and
      Poesio, Massimo",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "1926--1937",
    abstract = "The availability of large scale annotated corpora for coreference is essential to the development of the field. However, creating resources at the required scale via expert annotation would be too expensive. Crowdsourcing has been proposed as an alternative; but this approach has not been widely used for coreference. This paper addresses one crucial hurdle on the way to make this possible, by introducing a new model of annotation for aggregating crowdsourced anaphoric annotations. The model is evaluated along three dimensions: the accuracy of the inferred mention pairs, the quality of the post-hoc constructed silver chains, and the viability of using the silver chains as an alternative to the expert-annotated chains in training a state of the art coreference system. The results suggest that our model can extract from crowdsourced annotations coreference chains of comparable quality to those obtained with expert annotation.",
}

@inproceedings{poesio-artstein-2005-reliability,
    title = "The Reliability of Anaphoric Annotation, Reconsidered: Taking Ambiguity into Account",
    author = "Poesio, Massimo  and
      Artstein, Ron",
    booktitle = "Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    pages = "76--83",
}

@inproceedings{poesio-etal-2019-crowdsourced,
    title = "A Crowdsourced Corpus of Multiple Judgments and Disagreement on Anaphoric Interpretation",
    author = "Poesio, Massimo  and
      Chamberlain, Jon  and
      Paun, Silviu  and
      Yu, Juntao  and
      Uma, Alexandra  and
      Kruschwitz, Udo",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pages = "1778--1789",
    abstract = "We present a corpus of anaphoric information (coreference) crowdsourced through a game-with-a-purpose. The corpus, containing annotations for about 108,000 markables, is one of the largest corpora for coreference for English, and one of the largest crowdsourced NLP corpora, but its main feature is the large number of judgments per markable: 20 on average, and over 2.2M in total. This characteristic makes the corpus a unique resource for the study of disagreements on anaphoric interpretation. A second distinctive feature is its rich annotation scheme, covering singletons, expletives, and split-antecedent plurals. Finally, the corpus also comes with labels inferred using a recently proposed probabilistic model of annotation for coreference. The labels are of high quality and make it possible to successfully train a state of the art coreference resolver, including training on singletons and non-referring expressions. The annotation model can also result in more than one label, or no label, being proposed for a markable, thus serving as a baseline method for automatically identifying ambiguous markables. A preliminary analysis of the results is presented.",
}

@inproceedings{ng-2010-supervised,
    title = "Supervised Noun Phrase Coreference Research: The First Fifteen Years",
    author = "Ng, Vincent",
    booktitle = "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    pages = "1396--1411",
}

@article{fleiss1971measuring,
  title={Measuring nominal scale agreement among many raters.},
  author={Fleiss, Joseph L},
  journal={Psychological bulletin},
  volume={76},
  number={5},
  pages={378},
  year={1971},
  publisher={American Psychological Association}
}

@inproceedings{stenetorp2012brat,
  title={BRAT: a web-based tool for NLP-assisted text annotation},
  author={Stenetorp, Pontus and Pyysalo, Sampo and Topi{\'c}, Goran and Ohta, Tomoko and Ananiadou, Sophia and Tsujii, Jun'ichi},
  booktitle={Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={102--107},
  year={2012},
  organization={Association for Computational Linguistics}
}

@book{poesio2016anaphora,
  title={Anaphora resolution},
  author={Poesio, Massimo and Stuckardt, Roland and Versley, Yannick},
  year={2016},
  publisher={Springer}
}

@article{stolcke-etal-2000-dialogue,
    title = "Dialogue act modeling for automatic tagging and recognition of conversational speech",
    author = "Stolcke, Andreas  and
      Ries, Klaus  and
      Coccaro, Noah  and
      Shriberg, Elizabeth  and
      Bates, Rebecca  and
      Jurafsky, Daniel  and
      Taylor, Paul  and
      Martin, Rachel  and
      Van Ess-Dykema, Carol  and
      Meteer, Marie",
    journal = "Computational Linguistics",
    volume = "26",
    number = "3",
    year = "2000",
    pages = "339--374",
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}

@inproceedings{lewis-etal-2020-bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "7871--7880",
    abstract = "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.",
}


@inproceedings{yao2013recurrent,
  title={Recurrent neural networks for language understanding.},
  author={Yao, Kaisheng and Zweig, Geoffrey and Hwang, Mei-Yuh and Shi, Yangyang and Yu, Dong},
  booktitle={Interspeech},
  pages={2524--2528},
  year={2013}
}

@article{Gupta2006TheAS,
  title={The AT\&T spoken language understanding system},
  author={N. Gupta and G{\"o}khan T{\"u}r and Dilek Z. Hakkani-T{\"u}r and S. Bangalore and G. Riccardi and M. Gilbert},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  year={2006},
  volume={14},
  pages={213-222}
}

@inproceedings{henderson-etal-2014-word,
    title = "Word-Based Dialog State Tracking with Recurrent Neural Networks",
    author = "Henderson, Matthew  and
      Thomson, Blaise  and
      Young, Steve",
    booktitle = "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL})",
    month = jun,
    year = "2014",
    address = "Philadelphia, PA, U.S.A.",
    publisher = "Association for Computational Linguistics",
    pages = "292--299",
}

@inproceedings{peng-etal-2017-composite,
    title = "Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning",
    author = "Peng, Baolin  and
      Li, Xiujun  and
      Li, Lihong  and
      Gao, Jianfeng  and
      Celikyilmaz, Asli  and
      Lee, Sungjin  and
      Wong, Kam-Fai",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    pages = "2231--2240",
    abstract = "Building a dialogue agent to fulfill complex tasks, such as travel planning, is challenging because the agent has to learn to collectively complete multiple subtasks. For example, the agent needs to reserve a hotel and book a flight so that there leaves enough time for commute between arrival and hotel check-in. This paper addresses this challenge by formulating the task in the mathematical framework of options over Markov Decision Processes (MDPs), and proposing a hierarchical deep reinforcement learning approach to learning a dialogue manager that operates at different temporal scales. The dialogue manager consists of: (1) a top-level dialogue policy that selects among subtasks or options, (2) a low-level dialogue policy that selects primitive actions to complete the subtask given by the top-level policy, and (3) a global state tracker that helps ensure all cross-subtask constraints be satisfied. Experiments on a travel planning task with simulated and real users show that our approach leads to significant improvements over three baselines, two based on handcrafted rules and the other based on flat deep reinforcement learning.",
}

@inproceedings{wen-etal-2015-semantically,
    title = "Semantically Conditioned {LSTM}-based Natural Language Generation for Spoken Dialogue Systems",
    author = "Wen, Tsung-Hsien  and
      Ga{\v{s}}i{\'c}, Milica  and
      Mrk{\v{s}}i{\'c}, Nikola  and
      Su, Pei-Hao  and
      Vandyke, David  and
      Young, Steve",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    pages = "1711--1721",
}

@inproceedings{bordes2017learning,
title={Learning End-to-End Goal-Oriented Dialog},
author={Bordes, Antoine and Boureau, Y-Lan and Weston, Jason},
booktitle={International Conference on Learning Representations},
year={2017}
}

@inproceedings{benotti-blackburn-2021-grounding,
    title = "Grounding as a Collaborative Process",
    author = "Benotti, Luciana  and
      Blackburn, Patrick",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "515--531",
    abstract = "Collaborative grounding is a fundamental aspect of human-human dialog which allows people to negotiate meaning. In this paper we argue that it is missing from current deep learning approaches to dialog. Our central point is that making mistakes and being able to recover from them collaboratively is a key ingredient in grounding meaning. We illustrate the pitfalls of being unable to ground collaboratively, discuss what can be learned from the language acquisition and dialog systems literature, and reflect on how to move forward.",
}

@incollection{brennan1998grounding,
  address = {Hillsdale, NJ},
  author = {Brennan, Susan E.},
  booktitle = {Social and Cognitive Approaches to Interpersonal Communication},
  editor = {Fussell, S. R. and Kreuz, R. J.},
  pages = {201-225},
  publisher = {Lawrence Erlbaum},
  title = {The Grounding Problem in Conversations With and Through Computers},
  year = "1998"
}

@inproceedings{williams-etal-2017-hybrid,
    title = "Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning",
    author = "Williams, Jason D.  and
      Asadi, Kavosh  and
      Zweig, Geoffrey",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "665--677",
    abstract = "End-to-end learning of recurrent neural networks (RNNs) is an attractive solution for dialog systems; however, current techniques are data-intensive and require thousands of dialogs to learn simple behaviors. We introduce Hybrid Code Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as software and system action templates. Compared to existing end-to-end approaches, HCNs considerably reduce the amount of training data required, while retaining the key benefit of inferring a latent representation of dialog state. In addition, HCNs can be optimized with supervised learning, reinforcement learning, or a mixture of both. HCNs attain state-of-the-art performance on the bAbI dialog dataset (Bordes and Weston, 2016), and outperform two commercially deployed customer-facing dialog systems at our company.",
}

@article{andreas-etal-2020-task,
    title = "Task-Oriented Dialogue as Dataflow Synthesis",
    author = "Andreas, Jacob  and
      Bufe, John  and
      Burkett, David  and
      Chen, Charles  and
      Clausman, Josh  and
      Crawford, Jean  and
      Crim, Kate  and
      DeLoach, Jordan  and
      Dorner, Leah  and
      Eisner, Jason  and
      Fang, Hao  and
      Guo, Alan  and
      Hall, David  and
      Hayes, Kristin  and
      Hill, Kellie  and
      Ho, Diana  and
      Iwaszuk, Wendy  and
      Jha, Smriti  and
      Klein, Dan  and
      Krishnamurthy, Jayant  and
      Lanman, Theo  and
      Liang, Percy  and
      Lin, Christopher H.  and
      Lintsbakh, Ilya  and
      McGovern, Andy  and
      Nisnevich, Aleksandr  and
      Pauls, Adam  and
      Petters, Dmitrij  and
      Read, Brent  and
      Roth, Dan  and
      Roy, Subhro  and
      Rusak, Jesse  and
      Short, Beth  and
      Slomin, Div  and
      Snyder, Ben  and
      Striplin, Stephon  and
      Su, Yu  and
      Tellman, Zachary  and
      Thomson, Sam  and
      Vorobev, Andrei  and
      Witoszko, Izabela  and
      Wolfe, Jason  and
      Wray, Abby  and
      Zhang, Yuchen  and
      Zotov, Alexander",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    pages = "556--571",
}

@article{larsson2018grounding,
  title={Grounding as a side-effect of grounding},
  author={Larsson, Staffan},
  journal={Topics in cognitive science},
  volume={10},
  number={2},
  pages={389--408},
  year={2018},
  publisher={Wiley Online Library}
}

@article{pickering2004toward,
  title={Toward a mechanistic psychology of dialogue},
  author={Pickering, Martin J and Garrod, Simon},
  journal={Behavioral and brain sciences},
  volume={27},
  number={2},
  pages={169--190},
  year={2004},
  publisher={Cambridge University Press}
}

@article{steels_belpaeme_2005, 
  title={Coordinating perceptually grounded categories through language: a case study for colour}, 
  volume={28}, 
  number={4},
  journal={Behavioral and Brain Sciences}, 
  publisher={Cambridge University Press}, 
  author={Steels, Luc and Belpaeme, Tony}, 
  year={2005}, 
  pages={469489}
}

@book{Lakoff87,
  author = {Lakoff, George},
  publisher = {University of Chicago Press},
  title = {Women, Fire and Dangerous Things: What Categories Reveal About the Mind},
  year = 1987
}

@inproceedings{cho-may-2020-grounding,
    title = "Grounding Conversations with Improvised Dialogues",
    author = "Cho, Hyundong  and
      May, Jonathan",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "2398--2413",
    abstract = "Effective dialogue involves grounding, the process of establishing mutual knowledge that is essential for communication between people. Modern dialogue systems are not explicitly trained to build common ground, and therefore overlook this important aspect of communication. Improvisational theater (improv) intrinsically contains a high proportion of dialogue focused on building common ground, and makes use of the yes-and principle, a strong grounding speech act, to establish coherence and an actionable objective reality. We collect a corpus of more than 26,000 yes-and turns, transcribing them from improv dialogues and extracting them from larger, but more sparsely populated movie script dialogue corpora, via a bootstrapped classifier. We fine-tune chit-chat dialogue systems with our corpus to encourage more grounded, relevant conversation and confirm these findings with human evaluations.",
}

@article{harnad1990symbol,
  title={The symbol grounding problem},
  author={Harnad, Stevan},
  journal={Physica D: Nonlinear Phenomena},
  volume={42},
  number={1-3},
  pages={335--346},
  year={1990},
  publisher={Elsevier}
}

@article{keysar2000taking,
  title={Taking perspective in conversation: The role of mutual knowledge in comprehension},
  author={Keysar, Boaz and Barr, Dale J and Balin, Jennifer A and Brauner, Jason S},
  journal={Psychological Science},
  volume={11},
  number={1},
  pages={32--38},
  year={2000},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{alikhani-stone-2020-achieving,
    title = "Achieving Common Ground in Multi-modal Dialogue",
    author = "Alikhani, Malihe  and
      Stone, Matthew",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "10--15",
}

@book{Schelling1960,
  author = {Schelling, T.C.},
  publisher = {Harvard University Press},
  title = {{The Strategy of Conflict}},
  year = 1960
}

@article{grice1957meaning,
  title={Meaning},
  author={Grice, H Paul},
  journal={The philosophical review},
  volume={66},
  number={3},
  pages={377--388},
  year={1957},
  publisher={JSTOR}
}

@incollection{Clark1981-CLADKA,
  author = {Herbert H. Clark and Catherine R. Marshall},
  publisher = {Cambridge, UK: Cambridge University Press},
  pages = {10--63},
  year = {1981},
  title = {Definite Knowledge and Mutual Knowledge},
  editor = {Aravind K. Joshi and Bonnie L. Webber and Ivan A. Sag},
  booktitle = {Elements of Discourse Understanding}
}

@article{Brennan1996ConceptualPA,
  title={Conceptual pacts and lexical choice in conversation.},
  author={S. Brennan and H. H. Clark},
  journal={Journal of experimental psychology. Learning, memory, and cognition},
  year={1996},
  volume={22 6},
  pages={
          1482-93
        }
}

@book{fagin2003reasoning,
  title={Reasoning about knowledge},
  author={Fagin, Ronald and Moses, Yoram and Halpern, Joseph Y and Vardi, Moshe Y},
  year={2003},
  publisher={MIT press}
}

@article{lascarides2009formal,
  title={A formal semantic analysis of gesture},
  author={Lascarides, Alex and Stone, Matthew},
  journal={Journal of Semantics},
  volume={26},
  number={4},
  pages={393--449},
  year={2009},
  publisher={Oxford University Press}
}

@inproceedings{nakano-etal-2003-towards,
    title = "Towards a Model of Face-to-Face Grounding",
    author = "Nakano, Yukiko  and
      Reinstein, Gabe  and
      Stocky, Tom  and
      Cassell, Justine",
    booktitle = "Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2003",
    address = "Sapporo, Japan",
    publisher = "Association for Computational Linguistics",
    pages = "553--561",
}

@inproceedings{phy-etal-2020-deconstruct,
    title = "Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems",
    author = "Phy, Vitou  and
      Zhao, Yang  and
      Aizawa, Akiko",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    pages = "4164--4178",
    abstract = "Many automatic evaluation metrics have been proposed to score the overall quality of a response in open-domain dialogue. Generally, the overall quality is comprised of various aspects, such as relevancy, specificity, and empathy, and the importance of each aspect differs according to the task. For instance, specificity is mandatory in a food-ordering dialogue task, whereas fluency is preferred in a language-teaching dialogue system. However, existing metrics are not designed to cope with such flexibility. For example, BLEU score fundamentally relies only on word overlapping, whereas BERTScore relies on semantic similarity between reference and candidate response. Thus, they are not guaranteed to capture the required aspects, i.e., specificity. To design a metric that is flexible to a task, we first propose making these qualities manageable by grouping them into three groups: understandability, sensibleness, and likability, where likability is a combination of qualities that are essential for a task. We also propose a simple method to composite metrics of each aspect to obtain a single metric called USL-H, which stands for Understandability, Sensibleness, and Likability in Hierarchy. We demonstrated that USL-H score achieves good correlations with human judgment and maintains its configurability towards different aspects and metrics.",
}

@inproceedings{yan2016learning,
  title={Learning to respond with deep neural networks for retrieval-based human-computer conversation system},
  author={Yan, Rui and Song, Yiping and Wu, Hua},
  booktitle={Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval},
  pages={55--64},
  year={2016}
}

@article{cook2006current,
  title={Current concepts in validity and reliability for psychometric instruments: theory and application},
  author={Cook, David A and Beckman, Thomas J},
  journal={The American journal of medicine},
  volume={119},
  number={2},
  pages={166--e7},
  year={2006},
  publisher={Elsevier}
}

@article{zwaan1998situation,
  title={Situation models in language comprehension and memory.},
  author={Zwaan, Rolf A and Radvansky, Gabriel A},
  journal={Psychological bulletin},
  volume={123},
  number={2},
  pages={162},
  year={1998},
  publisher={American Psychological Association}
}

@article{GLENBERG198769,
  title = {Mental models contribute to foregrounding during text comprehension},
  journal = {Journal of Memory and Language},
  volume = {26},
  number = {1},
  pages = {69-83},
  year = {1987},
  issn = {0749-596X},
  author = {Arthur M Glenberg and Marion Meyer and Karen Lindem},
}

@article{ferguson1994properties,
  title={Properties of cognitive maps constructed from texts},
  author={Ferguson, Erika L and Hegarty, Mary},
  journal={Memory \& cognition},
  volume={22},
  number={4},
  pages={455--473},
  year={1994},
  publisher={Springer}
}

@incollection{Kamp1981-KAMATO-2,
  booktitle = {Formal Methods in the Study of Language},
  year = {1981},
  title = {A Theory of Truth and Semantic Representation, 277-322, JAG Groenendijk, TMV Janssen and MBJ Stokhof, Eds},
  publisher = {U of Amsterdam},
  author = {H. Kamp},
  editor = {Jeroen Groenendijk}
}

@book{kampreyle93,
  title = {From Discourse to Logic. Introduction to Modeltheoretic Semantics
  of Natural Language, Formal Logic and Discourse Representation Theory},
  publisher = {Kluwer},
  year = {1993},
  author = {Hans Kamp and Uwe Reyle},
  address = {Dordrecht}
}

@article{Grice1975LogicAC,
  title={Logic and conversation},
  author={Grice, H. Paul},
  journal={Syntax and Semantics},
  year={1975},
  volume={3},
  pages={41-58},
  publisher = {Academic Press}
}

@article{poesio1997conversational,
  title={Conversational actions and discourse situations},
  author={Poesio, Massimo and Traum, David R},
  journal={Computational intelligence},
  volume={13},
  number={3},
  pages={309--347},
  year={1997},
  publisher={Wiley Online Library}
}

@book{ginzburg2012interactive,
  title={The interactive stance},
  author={Ginzburg, Jonathan},
  year={2012},
  publisher={Oxford University Press}
}

@article{anderson1991hcrc,
  title={The HCRC map task corpus},
  author={Anderson, Anne H and Bader, Miles and Bard, Ellen Gurman and Boyle, Elizabeth and Doherty, Gwyneth and Garrod, Simon and Isard, Stephen and Kowtko, Jacqueline and McAllister, Jan and Miller, Jim and others},
  journal={Language and speech},
  volume={34},
  number={4},
  pages={351--366},
  year={1991},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{tokunaga-etal-2012-rex,
    title = "The {REX} corpora: A collection of multimodal corpora of referring expressions in collaborative problem solving dialogues",
    author = "Tokunaga, Takenobu and Iida, Ryu and Terai, Asuka and Kuriyama, Naoko",
    booktitle = "Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)",
    month = may,
    year = "2012",
    address = "Istanbul, Turkey",
    publisher = "European Language Resources Association (ELRA)",
    pages = "422--429"
}

@inproceedings{kollar-etal-2018-alexa,
    title = "The {A}lexa Meaning Representation Language",
    author = "Kollar, Thomas  and
      Berry, Danielle  and
      Stuart, Lauren  and
      Owczarzak, Karolina  and
      Chung, Tagyoung  and
      Mathias, Lambert  and
      Kayser, Michael  and
      Snow, Bradford  and
      Matsoukas, Spyros",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    pages = "177--184"
}

@inproceedings{Henderson2015,
    title = {Machine Learning for Dialog State Tracking: A Review},
    author  = {Matthew Henderson},
    year  = 2015,
    booktitle = {The First International Workshop on Machine Learning in Spoken Language Processing}
}

@article{Williams2016TheDS,
  title={The Dialog State Tracking Challenge Series: A Review},
  author={J. Williams and Antoine Raux and Matthew Henderson},
  journal={Dialogue Discourse},
  year={2016},
  volume={7},
  pages={4-33}
}

@inproceedings{dhingra-etal-2017-towards,
    title = "Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access",
    author = "Dhingra, Bhuwan  and
      Li, Lihong  and
      Li, Xiujun  and
      Gao, Jianfeng  and
      Chen, Yun-Nung  and
      Ahmed, Faisal  and
      Deng, Li",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "484--495"
}

@inproceedings{takanobu-etal-2019-guided,
    title = "Guided Dialog Policy Learning: Reward Estimation for Multi-Domain Task-Oriented Dialog",
    author = "Takanobu, Ryuichi  and
      Zhu, Hanlin  and
      Huang, Minlie",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pages = "100--110",
    abstract = "Dialog policy decides what and how a task-oriented dialog system will respond, and plays a vital role in delivering effective conversations. Many studies apply Reinforcement Learning to learn a dialog policy with the reward function which requires elaborate design and pre-specified user goals. With the growing needs to handle complex goals across multiple domains, such manually designed reward functions are not affordable to deal with the complexity of real-world tasks. To this end, we propose Guided Dialog Policy Learning, a novel algorithm based on Adversarial Inverse Reinforcement Learning for joint reward estimation and policy optimization in multi-domain task-oriented dialog. The proposed approach estimates the reward signal and infers the user goal in the dialog sessions. The reward estimator evaluates the state-action pairs so that it can guide the dialog policy at each dialog turn. Extensive experiments on a multi-domain dialog dataset show that the dialog policy guided by the learned reward function achieves remarkably higher task success than state-of-the-art baselines.",
}

@inproceedings{NEURIPS2019_c74d97b0,
 author = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
 volume = {32},
 year = {2019}
}

@inproceedings{ham-etal-2020-end,
    title = "End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using {GPT}-2",
    author = "Ham, Donghoon  and
      Lee, Jeong-Gwan  and
      Jang, Youngsoo  and
      Kim, Kee-Eung",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "583--592",
    abstract = "The goal-oriented dialogue system needs to be optimized for tracking the dialogue flow and carrying out an effective conversation under various situations to meet the user goal. The traditional approach to build such a dialogue system is to take a pipelined modular architecture, where its modules are optimized individually. However, such an optimization scheme does not necessarily yield the overall performance improvement of the whole system. On the other hand, end-to-end dialogue systems with monolithic neural architecture are often trained only with input-output utterances, without taking into account the entire annotations available in the corpus. This scheme makes it difficult for goal-oriented dialogues where the system needs to integrate with external systems or to provide interpretable information about why the system generated a particular response. In this paper, we present an end-to-end neural architecture for dialogue systems that addresses both challenges above. In the human evaluation, our dialogue system achieved the success rate of 68.32{\%}, the language understanding score of 4.149, and the response appropriateness score of 4.287, which ranked the system at the top position in the end-to-end multi-domain dialogue system task in the 8th dialogue systems technology challenge (DSTC8).",
}

@inproceedings{wen-etal-2017-network,
    title = "A Network-based End-to-End Trainable Task-oriented Dialogue System",
    author = "Wen, Tsung-Hsien  and
      Vandyke, David  and
      Mrk{\v{s}}i{\'c}, Nikola  and
      Ga{\v{s}}i{\'c}, Milica  and
      Rojas-Barahona, Lina M.  and
      Su, Pei-Hao  and
      Ultes, Stefan  and
      Young, Steve",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    pages = "438--449",
    abstract = "Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task-oriented dialogue systems requires creating multiple components and typically this involves either a large amount of handcrafting, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, text-out end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue systems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.",
}

@inproceedings{budzianowski-etal-2018-multiwoz,
    title = "{M}ulti{WOZ} - A Large-Scale Multi-Domain {W}izard-of-{O}z Dataset for Task-Oriented Dialogue Modelling",
    author = "Budzianowski, Pawe{\l}  and
      Wen, Tsung-Hsien  and
      Tseng, Bo-Hsiang  and
      Casanueva, I{\~n}igo  and
      Ultes, Stefan  and
      Ramadan, Osman  and
      Ga{\v{s}}i{\'c}, Milica",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "5016--5026",
    abstract = "Even though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available.To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.The contribution of this work apart from the open-sourced dataset is two-fold:firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.",
}

@article{lee2019multi,
  title={Multi-domain task-completion dialog challenge},
  author={Lee, S and Schulz, H and Atkinson, A and Gao, J and Suleman, K and El Asri, L and Adada, M and Huang, M and Sharma, S and Tay, W and others},
  journal={Dialog system technology challenges},
  volume={8},
  pages={9},
  year={2019}
}

@inproceedings{rastogi2020towards,
  title={Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset},
  author={Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={8689--8696},
  year={2020}
}

@InProceedings{shalyminov2020fast,
author = {Shalyminov, Igor and Sordoni, Alessandro and Atkinson, Adam and Schulz, Hannes},
title = {Fast Domain Adaptation For Goal-Oriented Dialogue Using A Hybrid Generative-Retrieval Transformer},
booktitle = {2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
year = {2020},
month = {April},
}

@article{chawla2021casino,
  title={CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems},
  author={Chawla, Kushal and Ramirez, Jaysa and Clever, Rene and Lucas, Gale and May, Jonathan and Gratch, Jonathan},
  journal={arXiv preprint arXiv:2103.15721},
  year={2021}
}

@inproceedings{lewis-etal-2017-deal,
    title = "Deal or No Deal? End-to-End Learning of Negotiation Dialogues",
    author = "Lewis, Mike  and
      Yarats, Denis  and
      Dauphin, Yann  and
      Parikh, Devi  and
      Batra, Dhruv",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    pages = "2443--2453",
    abstract = "Much of human dialogue occurs in semi-cooperative settings, where agents with different goals attempt to agree on common decisions. Negotiations require complex communication and reasoning skills, but success is easy to measure, making this an interesting task for AI. We gather a large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other{'}s reward functions must reach an agreement (or a deal) via natural language dialogue. For the first time, we show it is possible to train end-to-end models for negotiation, which must learn both linguistic and reasoning skills with no annotated dialogue states. We also introduce dialogue rollouts, in which the model plans ahead by simulating possible complete continuations of the conversation, and find that this technique dramatically improves performance. Our code and dataset are publicly available.",
}

@inproceedings{li2020noncollaborative,
  author    = {Yu Li and
               Kun Qian and
               Weiyan Shi and
               Zhou Yu},
  title     = {End-to-End Trainable Non-Collaborative Dialog System},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
               February 7-12, 2020},
  pages     = {8293--8302},
  publisher = {{AAAI} Press},
  year      = {2020},
  timestamp = {Tue, 02 Feb 2021 08:00:55 +0100},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zellers2019recognition,
  title={From recognition to cognition: Visual commonsense reasoning},
  author={Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6720--6731},
  year={2019}
}

@inproceedings{he-etal-2018-decoupling,
    title = "Decoupling Strategy and Generation in Negotiation Dialogues",
    author = "He, He  and
      Chen, Derek  and
      Balakrishnan, Anusha  and
      Liang, Percy",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "2333--2343",
    abstract = "We consider negotiation settings in which two agents use natural language to bargain on goods. Agents need to decide on both high-level strategy (e.g., proposing {\$}50) and the execution of that strategy (e.g., generating {``}The bike is brand new. Selling for just {\$}50!{''}). Recent work on negotiation trains neural models, but their end-to-end nature makes it hard to control their strategy, and reinforcement learning tends to lead to degenerate solutions. In this paper, we propose a modular approach based on coarse dialogue acts (e.g., propose(price=50)) that decouples strategy and generation. We show that we can flexibly set the strategy using supervised learning, reinforcement learning, or domain-specific knowledge without degeneracy, while our retrieval-based generation can maintain context-awareness and produce diverse utterances. We test our approach on the recently proposed DEALORNODEAL game, and we also collect a richer dataset based on real items on Craigslist. Human evaluation shows that our systems achieve higher task success rate and more human-like negotiation behavior than previous approaches.",
}

@inproceedings{wang-etal-2019-persuasion,
    title = "Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good",
    author = "Wang, Xuewei  and
      Shi, Weiyan  and
      Kim, Richard  and
      Oh, Yoojung  and
      Yang, Sijia  and
      Zhang, Jingwen  and
      Yu, Zhou",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    pages = "5635--5649",
    abstract = "Developing intelligent persuasive conversational agents to change people{'}s opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals{'} demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individuals{'} personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.",
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@inproceedings{zhang-etal-2020-dialogpt,
    title = "{DIALOGPT} : Large-Scale Generative Pre-training for Conversational Response Generation",
    author = "Zhang, Yizhe  and
      Sun, Siqi  and
      Galley, Michel  and
      Chen, Yen-Chun  and
      Brockett, Chris  and
      Gao, Xiang  and
      Gao, Jianfeng  and
      Liu, Jingjing  and
      Dolan, Bill",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "270--278",
    abstract = "We present a large, tunable neural conversational response generation model, DIALOGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent open-domain dialogue systems.",
}

@article{sacks1987preferences,
  title={On the preferences for agreement and contiguity in sequences in conversation},
  author={Sacks, Harvey},
  journal={Talk and social organisation},
  pages={54--69},
  year={1987},
  publisher={Multilingual Matters}
}

@article{vinyals2015neural,
  title={A neural conversational model},
  author={Vinyals, Oriol and Le, Quoc},
  journal={arXiv preprint arXiv:1506.05869},
  year={2015}
}

@inproceedings{zhang-etal-2018-personalizing,
    title = "Personalizing Dialogue Agents: {I} have a dog, do you have pets too?",
    author = "Zhang, Saizheng  and
      Dinan, Emily  and
      Urbanek, Jack  and
      Szlam, Arthur  and
      Kiela, Douwe  and
      Weston, Jason",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    pages = "2204--2213",
    abstract = "Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chit-chat more engaging by conditioning on profile information. We collect data and train models to (i)condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.",
}

@inproceedings{NEURIPS2019_4496bf24,
 author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
 volume = {32},
 year = {2019}
}



@inproceedings{wang-etal-2018-glue,
    title = "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    author = "Wang, Alex  and
      Singh, Amanpreet  and
      Michael, Julian  and
      Hill, Felix  and
      Levy, Omer  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pages = "353--355",
    abstract = "Human ability to understand language is \textit{general, flexible, and robust}. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.",
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{bender-koller-2020-climbing,
    title = "Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data",
    author = "Bender, Emily M.  and
      Koller, Alexander",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "5185--5198",
    abstract = "The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {``}understanding{''} language or capturing {``}meaning{''}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {``}Taking Stock of Where We{'}ve Been and Where We{'}re Going{''}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.",
}

@inproceedings{smith-etal-2020-put,
    title = "Can You Put it All Together: Evaluating Conversational Agents{'} Ability to Blend Skills",
    author = "Smith, Eric Michael  and
      Williamson, Mary  and
      Shuster, Kurt  and
      Weston, Jason  and
      Boureau, Y-Lan",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "2021--2030",
    abstract = "Being engaging, knowledgeable, and empathetic are all desirable general qualities in a conversational agent. Previous work has introduced tasks and datasets that aim to help agents to learn those qualities in isolation and gauge how well they can express them. But rather than being specialized in one single quality, a good open-domain conversational agent should be able to seamlessly blend them all into one cohesive conversational flow. In this work, we investigate several ways to combine models trained towards isolated capabilities, ranging from simple model aggregation schemes that require minimal additional training, to various forms of multi-task training that encompass several skills at all training stages. We further propose a new dataset, BlendedSkillTalk, to analyze how these capabilities would mesh together in a natural conversation, and compare the performance of different architectures and training schemes. Our experiments show that multi-tasking over several tasks that focus on particular capabilities results in better blended conversation performance compared to models trained on a single skill, and that both unified or two-stage approaches perform well if they are constructed to avoid unwanted bias in skill selection or are fine-tuned on our new task.",
}

@article{Deriu2020SurveyOE,
  title={Survey on evaluation methods for dialogue systems},
  author={Jan Deriu and {\'A}lvaro Rodrigo and Arantxa Otegi and Guillermo Echegoyen and S. Rosset and Eneko Agirre and Mark Cieliebak},
  journal={Artificial Intelligence Review},
  year={2020},
  volume={54},
  pages={755 - 810}
}

@inproceedings{walker-etal-1997-paradise,
    title = "{PARADISE}: A Framework for Evaluating Spoken Dialogue Agents",
    author = "Walker, Marilyn A.  and
      Litman, Diane J.  and
      Kamm, Candace A.  and
      Abella, Alicia",
    booktitle = "35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = jul,
    year = "1997",
    address = "Madrid, Spain",
    publisher = "Association for Computational Linguistics",
    pages = "271--280",
}

@inproceedings{das2017visdialrl,
  title={Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning},
  author={Abhishek Das and Satwik Kottur and Jos\'e M.F. Moura and
    Stefan Lee and Dhruv Batra},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2017}
}

@inproceedings{nltkbook,
 author = {Loper, Edward and Bird, Steven},
 title = {{NLTK}: The Natural Language Toolkit},
 booktitle = {Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics - Volume 1},
 series = {ETMTNLP '02},
 year = {2002},
 location = {Philadelphia, Pennsylvania},
 pages = {63--70},
 numpages = {8},
 acmid = {1118117},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{serban2016hierarchical,
 author = {Serban, Iulian V. and Sordoni, Alessandro and Bengio, Yoshua and Courville, Aaron and Pineau, Joelle},
 title = {Building End-to-end Dialogue Systems Using Generative Hierarchical Neural Network Models},
 booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
 series = {AAAI'16},
 year = {2016},
 location = {Phoenix, Arizona},
 pages = {3776--3783},
 numpages = {8},
 acmid = {3016435},
 publisher = {AAAI Press},
} 

@article{Fodor1988ConnectionismAC,
  title={Connectionism and cognitive architecture: A critical analysis},
  author={J. Fodor and Z. Pylyshyn},
  journal={Cognition},
  year={1988},
  volume={28},
  pages={3-71}
}

@inproceedings{Lake2018GeneralizationWS,
  title={Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks},
  author={B. Lake and Marco Baroni},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2018}
}

@article{etzioni2008open,
  title={Open information extraction from the web},
  author={Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S},
  journal={Communications of the ACM},
  volume={51},
  number={12},
  pages={68--74},
  year={2008},
  publisher={ACM New York, NY, USA}
}

@InProceedings{kazemzadeh2014referit,
  author =  "Kazemzadeh, Sahar
    and Ordonez, Vicente
    and Matten, Mark
    and Berg, Tamara",
  title =   "Refer{I}t{G}ame: Referring to Objects in Photographs of Natural Scenes",
  booktitle =   "Proceedings of the 2014 Conference on Empirical Methods in Natural      Language Processing (EMNLP)    ",
  year =  "2014",
  publisher =   "Association for Computational Linguistics",
  pages =   "787--798",
  location =  "Doha, Qatar",
}

@article{linzen-etal-2016-assessing,
    title = "Assessing the Ability of {LSTM}s to Learn Syntax-Sensitive Dependencies",
    author = "Linzen, Tal  and
      Dupoux, Emmanuel  and
      Goldberg, Yoav",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "4",
    year = "2016",
    pages = "521--535",
    abstract = "The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture{'}s grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1{\%} errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.",
}

@inproceedings{koschmann2003reconsidering,
  title={Reconsidering common ground},
  author={Koschmann, Timothy and LeBaron, Curtis D},
  booktitle={ECSCW 2003},
  pages={81--98},
  year={2003},
  organization={Springer}
}

@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}

@article{lipton2016mythos,
  title={The mythos of model interpretability},
  author={Lipton, Zachary C},
  journal={arXiv preprint arXiv:1606.03490},
  year={2016}
}


@article{belinkov-glass-2019-analysis,
    title = "Analysis Methods in Neural Language Processing: A Survey",
    author = "Belinkov, Yonatan  and
      Glass, James",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    pages = "49--72"
}

@inproceedings{pradhan2011conll,
  title={Conll-2011 shared task: Modeling unrestricted coreference in ontonotes},
  author={Pradhan, Sameer and Ramshaw, Lance and Marcus, Mitchell and Palmer, Martha and Weischedel, Ralph and Xue, Nianwen},
  booktitle={Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task},
  pages={1--27},
  year={2011},
  organization={Association for Computational Linguistics}
}

@inproceedings{recasens-etal-2012-annotating,
    title = "Annotating Near-Identity from Coreference Disagreements",
    author = "Recasens, Marta  and
      Mart{\'\i}, M. Ant{\`o}nia  and
      Orasan, Constantin",
    booktitle = "Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}-2012)",
    year = "2012",
    address = "Istanbul, Turkey",
    publisher = "European Languages Resources Association (ELRA)",
    pages = "165--172",
}

@Article{linzen2016assessing,
  author =  "Linzen, Tal
    and Dupoux, Emmanuel
    and Goldberg, Yoav",
  title =   "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies",
  journal =   "Transactions of the Association for Computational Linguistics",
  year =  "2016",
  volume =  "4",
  pages =   "521--535",
}
